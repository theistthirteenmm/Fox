# ๐ฆ ุฑุงูููุง ุณุฑุน ุฑูุจุงู

## ูุฑุงุญู ุฑุงูโุงูุฏุงุฒ (5 ุฏููู)

### 1. ูุตุจ Ollama
```cmd
# ุจุฑู ุจู https://ollama.ai ู Windows installer ุฑู ุฏุงูููุฏ ฺฉู
# ุจุนุฏ ุงุฒ ูุตุจ:
ollama serve
```

### 2. ุฏุงูููุฏ ูุฏู ูุงุฑุณ
```cmd
# ูุฏู ูุงุฑุณ ูพุดููุงุฏ (8.5GB):
ollama pull partai/dorna-llama3:8b-instruct-q8_0

# ุง ูุฏูโูุง ุฏฺฏุฑ:
ollama pull llama3.2:3b        # ุณุจฺฉ (2GB)
ollama pull codellama:13b      # ฺฉุฏ (7GB)
```

### 3. ุฑุงูโุงูุฏุงุฒ ุฑูุจุงู
```cmd
# ุฑูุด ุณุงุฏู (ูพุดููุงุฏ):
start_robah.bat

# ุง ุฏุณุช:
# Terminal 1: python backend/main.py
# Terminal 2: cd frontend && npm start
```

### 4. ุฏุณุชุฑุณ
- **ุฑุงุจุท ูุจ**: http://localhost:3000
- **API**: http://localhost:8000
- **ูุณุชูุฏุงุช**: http://localhost:8000/docs

## ูฺฺฏโูุง ูุนุงู โ

๐ฏ **ูุณุชู AI**: ุณุณุชู ฺูุฏ ูุฏูู ููุดููุฏ  
๐ง **ุญุงูุธู**: ุฐุฎุฑู ู ุจุงุฒุงุจ ูฺฉุงููุงุช  
๐ญ **ุดุฎุตุช**: ุฑุดุฏ ู ุชุทุจู ุจุง ฺฉุงุฑุจุฑ  
๐ค **ุตูุช**: ุถุจุท ู ุชุจุฏู ุจู ูุชู  
๐ **ูุงู**: ุขูพููุฏ ู ูพุฑุฏุงุฒุด ูุงูโูุง  
๐ **ูุจ**: ุฌุณุชุฌู ุงูุชุฑูุช  
๐ป **ฺฉุฏ**: ุชุญูู ุจุฑูุงููโููุณ  
๐ญ **Thinking**: ูพุงูโูุง ูุงู ุฏุฑ ูพุฑุฏุงุฒุด  

## ูุฏูโูุง ูพุดุชุจุงู ุดุฏู

### ุณุณุชู ฺูุฏ ูุฏูู
- **ูุงุฑุณ**: `partai/dorna-llama3:8b-instruct-q8_0` (8.5GB)
- **ุนููู**: `llama4:scout` (50GB) - ูุฏุฑุชููุฏ
- **ฺฉุฏ**: `codellama:13b` (7GB) - ุจุฑูุงููโููุณ
- **ุณุฑุน**: `llama4:scout-q4` (10GB) - ูพุงุณุฎ ุณุฑุน

### ุฏุงูููุฏ ููู ูุฏูโูุง
```cmd
# ุฏุงูููุฏ ุฎูุฏฺฉุงุฑ ููู ูุฏูโูุง (67GB):
download_models.bat
```

## ุนุจโุงุจ ุณุฑุน

### ุจุฑุฑุณ ุณุณุชู
```cmd
# ุจุฑุฑุณ Ollama
curl http://localhost:11434/api/tags

# ุจุฑุฑุณ Backend  
curl http://localhost:8000/status

# ูุณุช ูุฏูโูุง
ollama list
```

### ูุดฺฉูุงุช ุฑุงุฌ

**Frontend ููโุขุฏ ุจุงูุง:**
```cmd
cd frontend
npm install
npm start
```

**Backend ุฎุทุง ูโุฏู:**
```cmd
pip install -r requirements.txt
python backend/main.py
```

**ูฺฉุฑูููู ฺฉุงุฑ ููโฺฉูู:**
- ุจุฑู ุจู: http://localhost:8000/speech/debug
- Console ูุฑูุฑฺฏุฑ ุฑู ุจุงุฒ ฺฉู (F12)
- ุฏฺฉูู ูฺฉุฑูููู ุฑู ุชุณุช ฺฉู

## ูุงุฒููุฏโูุง ุณุณุชู

- **RAM**: ุญุฏุงูู 8GB (16GB ุจูุชุฑ)
- **ูุถุง ุฏุณฺฉ**: 10-70GB (ุจุณุชู ุจู ูุฏูโูุง)
- **CPU**: ูุฑ ูพุฑุฏุงุฒูุฏู ูุฏุฑู
- **OS**: Windows 10/11

## ูฺฺฏโูุง ุฑูุจุงู

โ **ุญุงูุธู ููุดููุฏ**: ููู ูฺฉุงููุงุช ุฑู ุจู ุฎุงุทุฑ ูโุณูพุงุฑู  
โ **ุฑุดุฏ ุดุฎุตุช**: ุจุง ูุฑ ูฺฉุงููู ููโุชุฑ ูโุดู  
โ **ูพุดุชุจุงู ูุงุฑุณ**: ฺฉุงููุงู ูุงุฑุณ ุตุญุจุช ูโฺฉูู  
โ **ุงุฏฺฏุฑ ูุฏุงูู**: ุงุฒ ุชุนุงููุงุช ุงุฏ ูโฺฏุฑู  
โ **ุฑุงุจุท ุฒุจุง**: ุทุฑุงุญ ูุฏุฑู ู ฺฉุงุฑุจุฑูพุณูุฏ  
โ **ุณุณุชู ฺูุฏ ูุฏูู**: ุงูุชุฎุงุจ ููุดููุฏ ูุฏู ุจุฑ ุงุณุงุณ ูุงุฒ

---

๐ **ุฑูุจุงู ุขูุงุฏู ุงุณุช ุชุง ุจุง ุดูุง ุฑุดุฏ ฺฉูุฏ!**

๐ **ุฑุงูููุงูุง ุจุดุชุฑ:**
- `INSTALL.md` - ูุตุจ ฺฉุงูู
- `MODELS_DOWNLOAD_GUIDE.md` - ุฑุงูููุง ูุฏูโูุง  
- `docs/` - ูุณุชูุฏุงุช ูู