"""
ğŸ§  Ø³ÛŒØ³ØªÙ… Cache Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø±ÙˆØ¨Ø§Ù‡
Ú©Ø´ Ú©Ø±Ø¯Ù† Ù¾Ø§Ø³Ø®â€ŒÙ‡Ø§ Ùˆ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯
"""

import hashlib
import json
import time
from typing import Dict, Optional, List
from datetime import datetime, timedelta
import redis
import pickle

class SmartCache:
    def __init__(self):
        # Redis Ø¨Ø±Ø§ÛŒ cache Ø³Ø±ÛŒØ¹ (Ø§Ø®ØªÛŒØ§Ø±ÛŒ)
        try:
            self.redis_client = redis.Redis(host='localhost', port=6379, db=0)
            self.use_redis = True
            print("ğŸ”´ Redis cache ÙØ¹Ø§Ù„ Ø´Ø¯")
        except:
            self.use_redis = False
            print("ğŸ’¾ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² cache Ù…Ø­Ù„ÛŒ")
        
        # Cache Ù…Ø­Ù„ÛŒ
        self.local_cache = {}
        self.cache_stats = {
            "hits": 0,
            "misses": 0,
            "total_requests": 0
        }
        
        # ØªÙ†Ø¸ÛŒÙ…Ø§Øª cache
        self.max_cache_size = 1000
        self.default_ttl = 3600  # 1 Ø³Ø§Ø¹Øª
        self.similarity_threshold = 0.85
        
    def _generate_cache_key(self, message: str, context: List[Dict] = None) -> str:
        """ØªÙˆÙ„ÛŒØ¯ Ú©Ù„ÛŒØ¯ Ù…Ù†Ø­ØµØ± Ø¨Ù‡ ÙØ±Ø¯ Ø¨Ø±Ø§ÛŒ cache"""
        # Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ù¾ÛŒØ§Ù…
        normalized = message.lower().strip()
        
        # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† context Ø§Ú¯Ø± Ù…Ù‡Ù… Ø¨Ø§Ø´Ø¯
        context_hash = ""
        if context:
            context_str = json.dumps(context, sort_keys=True)
            context_hash = hashlib.md5(context_str.encode()).hexdigest()[:8]
        
        # ØªÙˆÙ„ÛŒØ¯ hash
        full_key = f"{normalized}_{context_hash}"
        return hashlib.sha256(full_key.encode()).hexdigest()[:16]
    
    def get_cached_response(self, message: str, context: List[Dict] = None) -> Optional[Dict]:
        """Ø¯Ø±ÛŒØ§ÙØª Ù¾Ø§Ø³Ø® Ø§Ø² cache"""
        self.cache_stats["total_requests"] += 1
        
        cache_key = self._generate_cache_key(message, context)
        
        # Ø¬Ø³ØªØ¬Ùˆ Ø¯Ø± Redis
        if self.use_redis:
            try:
                cached_data = self.redis_client.get(cache_key)
                if cached_data:
                    result = pickle.loads(cached_data)
                    self.cache_stats["hits"] += 1
                    print(f"ğŸ¯ Cache hit: {message[:30]}...")
                    return result
            except Exception as e:
                print(f"Ø®Ø·Ø§ Ø¯Ø± Redis: {e}")
        
        # Ø¬Ø³ØªØ¬Ùˆ Ø¯Ø± cache Ù…Ø­Ù„ÛŒ
        if cache_key in self.local_cache:
            cached_item = self.local_cache[cache_key]
            
            # Ø¨Ø±Ø±Ø³ÛŒ Ø§Ù†Ù‚Ø¶Ø§
            if datetime.now() < cached_item["expires_at"]:
                self.cache_stats["hits"] += 1
                print(f"ğŸ¯ Local cache hit: {message[:30]}...")
                return cached_item["data"]
            else:
                # Ø­Ø°Ù Ø¢ÛŒØªÙ… Ù…Ù†Ù‚Ø¶ÛŒ Ø´Ø¯Ù‡
                del self.local_cache[cache_key]
        
        # Ø¬Ø³ØªØ¬ÙˆÛŒ similarity-based
        similar_response = self._find_similar_cached_response(message)
        if similar_response:
            self.cache_stats["hits"] += 1
            print(f"ğŸ” Similar cache hit: {message[:30]}...")
            return similar_response
        
        self.cache_stats["misses"] += 1
        return None
    
    def cache_response(self, message: str, response: Dict, context: List[Dict] = None, ttl: int = None):
        """Ø°Ø®ÛŒØ±Ù‡ Ù¾Ø§Ø³Ø® Ø¯Ø± cache"""
        cache_key = self._generate_cache_key(message, context)
        ttl = ttl or self.default_ttl
        
        cache_data = {
            "response": response,
            "timestamp": datetime.now().isoformat(),
            "message": message,
            "context_size": len(context) if context else 0
        }
        
        # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± Redis
        if self.use_redis:
            try:
                self.redis_client.setex(
                    cache_key, 
                    ttl, 
                    pickle.dumps(cache_data)
                )
            except Exception as e:
                print(f"Ø®Ø·Ø§ Ø¯Ø± Ø°Ø®ÛŒØ±Ù‡ Redis: {e}")
        
        # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± cache Ù…Ø­Ù„ÛŒ
        expires_at = datetime.now() + timedelta(seconds=ttl)
        self.local_cache[cache_key] = {
            "data": cache_data,
            "expires_at": expires_at
        }
        
        # Ù…Ø¯ÛŒØ±ÛŒØª Ø§Ù†Ø¯Ø§Ø²Ù‡ cache
        self._manage_cache_size()
        
        print(f"ğŸ’¾ Cached: {message[:30]}...")
    
    def _find_similar_cached_response(self, message: str) -> Optional[Dict]:
        """Ø¬Ø³ØªØ¬ÙˆÛŒ Ù¾Ø§Ø³Ø® Ù…Ø´Ø§Ø¨Ù‡ Ø¯Ø± cache"""
        message_words = set(message.lower().split())
        
        best_match = None
        best_similarity = 0
        
        for cached_item in self.local_cache.values():
            if datetime.now() >= cached_item["expires_at"]:
                continue
                
            cached_message = cached_item["data"]["message"]
            cached_words = set(cached_message.lower().split())
            
            # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´Ø¨Ø§Ù‡Øª Jaccard
            intersection = len(message_words & cached_words)
            union = len(message_words | cached_words)
            
            if union > 0:
                similarity = intersection / union
                
                if similarity > best_similarity and similarity >= self.similarity_threshold:
                    best_similarity = similarity
                    best_match = cached_item["data"]
        
        return best_match
    
    def _manage_cache_size(self):
        """Ù…Ø¯ÛŒØ±ÛŒØª Ø§Ù†Ø¯Ø§Ø²Ù‡ cache"""
        if len(self.local_cache) > self.max_cache_size:
            # Ø­Ø°Ù Ù‚Ø¯ÛŒÙ…ÛŒâ€ŒØªØ±ÛŒÙ† Ø¢ÛŒØªÙ…â€ŒÙ‡Ø§
            sorted_items = sorted(
                self.local_cache.items(),
                key=lambda x: x[1]["expires_at"]
            )
            
            # Ø­Ø°Ù 20% Ù‚Ø¯ÛŒÙ…ÛŒâ€ŒØªØ±ÛŒÙ† Ø¢ÛŒØªÙ…â€ŒÙ‡Ø§
            remove_count = int(self.max_cache_size * 0.2)
            for i in range(remove_count):
                if i < len(sorted_items):
                    del self.local_cache[sorted_items[i][0]]
    
    def get_cache_stats(self) -> Dict:
        """Ø¢Ù…Ø§Ø± cache"""
        hit_rate = 0
        if self.cache_stats["total_requests"] > 0:
            hit_rate = self.cache_stats["hits"] / self.cache_stats["total_requests"]
        
        return {
            **self.cache_stats,
            "hit_rate": hit_rate,
            "cache_size": len(self.local_cache),
            "redis_enabled": self.use_redis
        }
    
    def clear_cache(self):
        """Ù¾Ø§Ú© Ú©Ø±Ø¯Ù† Ú©Ø§Ù…Ù„ cache"""
        self.local_cache.clear()
        if self.use_redis:
            try:
                self.redis_client.flushdb()
            except:
                pass
        print("ğŸ—‘ï¸ Cache Ù¾Ø§Ú© Ø´Ø¯")

# Instance Ø³Ø±Ø§Ø³Ø±ÛŒ
smart_cache = SmartCache()