"""
ðŸŽ¯ Ù…Ø¯ÛŒØ± Context Ù‡ÙˆØ´Ù…Ù†Ø¯
ØªØ­Ù„ÛŒÙ„ Ùˆ Ù…Ø¯ÛŒØ±ÛŒØª context Ù…Ú©Ø§Ù„Ù…Ù‡ Ø¨Ø±Ø§ÛŒ Ù¾Ø§Ø³Ø®â€ŒÙ‡Ø§ÛŒ Ø¨Ù‡ØªØ±
"""

import json
from typing import Dict, List, Optional, Tuple
from datetime import datetime, timedelta
from dataclasses import dataclass
from enum import Enum
import re
from collections import defaultdict

class ContextType(Enum):
    CONVERSATION = "conversation"
    TOPIC = "topic"
    EMOTION = "emotion"
    TASK = "task"
    REFERENCE = "reference"

class ContextImportance(Enum):
    LOW = 1
    MEDIUM = 2
    HIGH = 3
    CRITICAL = 4

@dataclass
class ContextItem:
    id: str
    type: ContextType
    content: str
    importance: ContextImportance
    timestamp: datetime
    metadata: Dict
    expires_at: Optional[datetime] = None
    usage_count: int = 0

class ContextManager:
    def __init__(self):
        self.contexts = {}  # Dict[str, ContextItem]
        self.context_history = []  # List[str] - IDs Ù…Ø±ØªØ¨ Ø´Ø¯Ù‡
        self.topic_contexts = defaultdict(list)  # Dict[str, List[str]]
        self.active_contexts = []  # List[str] - context Ù‡Ø§ÛŒ ÙØ¹Ø§Ù„
        
        # ØªÙ†Ø¸ÛŒÙ…Ø§Øª
        self.max_contexts = 100
        self.max_active_contexts = 10
        self.default_context_ttl = timedelta(hours=2)
        
        # Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ ØªØ´Ø®ÛŒØµ context
        self.context_patterns = {
            "question": [r"\?", r"Ú†ÛŒ", r"Ú©ÛŒ", r"Ú©Ø¬Ø§", r"Ú†Ø·ÙˆØ±", r"Ú†Ø±Ø§"],
            "request": [r"Ù„Ø·ÙØ§", r"Ù…ÛŒâ€ŒØªÙˆÙ†ÛŒ", r"Ú©Ù…Ú©", r"Ø¨Ú¯Ùˆ", r"ØªÙˆØ¶ÛŒØ­"],
            "emotion": [r"Ø®ÙˆØ´Ø­Ø§Ù„", r"Ù†Ø§Ø±Ø§Ø­Øª", r"Ø¹ØµØ¨Ø§Ù†ÛŒ", r"Ø®Ø³ØªÙ‡", r"Ù‡ÛŒØ¬Ø§Ù†"],
            "reference": [r"Ø§ÛŒÙ†", r"Ø¢Ù†", r"Ù‡Ù…ÙˆÙ†", r"Ù‚Ø¨Ù„ÛŒ", r"Ú¯ÙØªÛŒ"]
        }
        
        print("ðŸŽ¯ Context Manager Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø´Ø¯")
    
    def add_context(self, 
                   content: str, 
                   context_type: ContextType,
                   importance: ContextImportance = ContextImportance.MEDIUM,
                   metadata: Dict = None,
                   ttl: timedelta = None) -> str:
        """Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† context Ø¬Ø¯ÛŒØ¯"""
        
        context_id = f"{context_type.value}_{datetime.now().timestamp()}"
        ttl = ttl or self.default_context_ttl
        
        context_item = ContextItem(
            id=context_id,
            type=context_type,
            content=content,
            importance=importance,
            timestamp=datetime.now(),
            metadata=metadata or {},
            expires_at=datetime.now() + ttl
        )
        
        self.contexts[context_id] = context_item
        self.context_history.append(context_id)
        
        # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø¨Ù‡ topic contexts
        if context_type == ContextType.TOPIC:
            topic = metadata.get("topic", "general")
            self.topic_contexts[topic].append(context_id)
        
        # Ù…Ø¯ÛŒØ±ÛŒØª Ø§Ù†Ø¯Ø§Ø²Ù‡
        self._manage_context_size()
        
        print(f"ðŸ“ Context Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯: {context_type.value} - {content[:50]}...")
        return context_id
    
    def get_relevant_contexts(self, 
                            message: str, 
                            max_contexts: int = 5) -> List[ContextItem]:
        """Ø¯Ø±ÛŒØ§ÙØª context Ù‡Ø§ÛŒ Ù…Ø±ØªØ¨Ø· Ø¨Ø§ Ù¾ÛŒØ§Ù…"""
        
        relevant_contexts = []
        message_lower = message.lower()
        
        # ØªØ­Ù„ÛŒÙ„ Ù¾ÛŒØ§Ù… Ø¨Ø±Ø§ÛŒ ØªØ´Ø®ÛŒØµ Ù†ÙˆØ¹ context Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø²
        needed_types = self._analyze_message_context_needs(message)
        
        # Ø¬Ø³ØªØ¬Ùˆ Ø¯Ø± context Ù‡Ø§ÛŒ ÙØ¹Ø§Ù„
        for context_id in self.active_contexts:
            if context_id in self.contexts:
                context = self.contexts[context_id]
                
                # Ø¨Ø±Ø±Ø³ÛŒ Ø§Ù†Ù‚Ø¶Ø§
                if context.expires_at and datetime.now() > context.expires_at:
                    continue
                
                # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ù…ØªÛŒØ§Ø² relevance
                relevance_score = self._calculate_relevance(message, context)
                
                if relevance_score > 0.3:  # threshold
                    relevant_contexts.append((context, relevance_score))
        
        # Ù…Ø±ØªØ¨â€ŒØ³Ø§Ø²ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§Ù…ØªÛŒØ§Ø² Ùˆ Ø§Ù‡Ù…ÛŒØª
        relevant_contexts.sort(
            key=lambda x: (x[1], x[0].importance.value), 
            reverse=True
        )
        
        # Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†Ø¯Ù† Ø¨Ù‡ØªØ±ÛŒÙ† context Ù‡Ø§
        result = [ctx for ctx, score in relevant_contexts[:max_contexts]]
        
        # Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ usage_count
        for context in result:
            context.usage_count += 1
        
        return result
    
    def _analyze_message_context_needs(self, message: str) -> List[ContextType]:
        """ØªØ­Ù„ÛŒÙ„ Ù¾ÛŒØ§Ù… Ø¨Ø±Ø§ÛŒ ØªØ´Ø®ÛŒØµ Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø§Ù†ÙˆØ§Ø¹ context"""
        needed_types = []
        message_lower = message.lower()
        
        # Ø¨Ø±Ø±Ø³ÛŒ Ø§Ù„Ú¯ÙˆÙ‡Ø§
        for pattern_type, patterns in self.context_patterns.items():
            for pattern in patterns:
                if re.search(pattern, message_lower):
                    if pattern_type == "reference":
                        needed_types.append(ContextType.REFERENCE)
                    elif pattern_type == "emotion":
                        needed_types.append(ContextType.EMOTION)
                    elif pattern_type in ["question", "request"]:
                        needed_types.append(ContextType.CONVERSATION)
                    break
        
        # Ù‡Ù…ÛŒØ´Ù‡ conversation context Ù†ÛŒØ§Ø² Ø§Ø³Øª
        if ContextType.CONVERSATION not in needed_types:
            needed_types.append(ContextType.CONVERSATION)
        
        return needed_types
    
    def _calculate_relevance(self, message: str, context: ContextItem) -> float:
        """Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ù…ØªÛŒØ§Ø² relevance Ø¨ÛŒÙ† Ù¾ÛŒØ§Ù… Ùˆ context"""
        score = 0.0
        message_words = set(message.lower().split())
        context_words = set(context.content.lower().split())
        
        # Ø´Ø¨Ø§Ù‡Øª Ú©Ù„Ù…Ø§Øª
        if context_words and message_words:
            intersection = len(message_words & context_words)
            union = len(message_words | context_words)
            jaccard_similarity = intersection / union if union > 0 else 0
            score += jaccard_similarity * 0.4
        
        # Ø§Ù…ØªÛŒØ§Ø² Ø§Ù‡Ù…ÛŒØª
        importance_score = context.importance.value / 4.0
        score += importance_score * 0.3
        
        # Ø§Ù…ØªÛŒØ§Ø² Ø²Ù…Ø§Ù†ÛŒ (context Ù‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯ØªØ± Ø§Ù…ØªÛŒØ§Ø² Ø¨ÛŒØ´ØªØ±)
        time_diff = datetime.now() - context.timestamp
        time_score = max(0, 1 - (time_diff.total_seconds() / 3600))  # Ú©Ø§Ù‡Ø´ Ø¯Ø± 1 Ø³Ø§Ø¹Øª
        score += time_score * 0.2
        
        # Ø§Ù…ØªÛŒØ§Ø² Ø§Ø³ØªÙØ§Ø¯Ù‡ (context Ù‡Ø§ÛŒ Ù¾Ø±Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ù…ØªÛŒØ§Ø² Ø¨ÛŒØ´ØªØ±)
        usage_score = min(1.0, context.usage_count / 10.0)
        score += usage_score * 0.1
        
        return min(1.0, score)
    
    def update_active_contexts(self, message: str, response: str):
        """Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ context Ù‡Ø§ÛŒ ÙØ¹Ø§Ù„ Ø¨Ø¹Ø¯ Ø§Ø² Ù…Ú©Ø§Ù„Ù…Ù‡"""
        
        # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ù¾ÛŒØ§Ù… Ú©Ø§Ø±Ø¨Ø±
        user_context_id = self.add_context(
            content=message,
            context_type=ContextType.CONVERSATION,
            importance=ContextImportance.MEDIUM,
            metadata={"role": "user"}
        )
        
        # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ù¾Ø§Ø³Ø® AI
        ai_context_id = self.add_context(
            content=response,
            context_type=ContextType.CONVERSATION,
            importance=ContextImportance.MEDIUM,
            metadata={"role": "assistant"}
        )
        
        # Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ context Ù‡Ø§ÛŒ ÙØ¹Ø§Ù„
        self.active_contexts.extend([user_context_id, ai_context_id])
        
        # Ù…Ø­Ø¯ÙˆØ¯ Ú©Ø±Ø¯Ù† ØªØ¹Ø¯Ø§Ø¯ context Ù‡Ø§ÛŒ ÙØ¹Ø§Ù„
        if len(self.active_contexts) > self.max_active_contexts:
            # Ø­Ø°Ù Ù‚Ø¯ÛŒÙ…ÛŒâ€ŒØªØ±ÛŒÙ† context Ù‡Ø§
            self.active_contexts = self.active_contexts[-self.max_active_contexts:]
        
        # ØªØ´Ø®ÛŒØµ Ùˆ Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† topic context
        self._extract_and_add_topic_context(message, response)
    
    def _extract_and_add_topic_context(self, message: str, response: str):
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ùˆ Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† topic context"""
        
        # Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ø¨Ø±Ø§ÛŒ ØªØ´Ø®ÛŒØµ topic
        topic_keywords = {
            "Ø¨Ø±Ù†Ø§Ù…Ù‡â€ŒÙ†ÙˆÛŒØ³ÛŒ": ["Ú©Ø¯", "Ø¨Ø±Ù†Ø§Ù…Ù‡", "python", "javascript", "programming"],
            "Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ": ["ai", "Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ", "machine learning", "Ù…Ø¯Ù„"],
            "Ø¹Ù„Ù…": ["Ø¹Ù„Ù…", "ÙÛŒØ²ÛŒÚ©", "Ø´ÛŒÙ…ÛŒ", "Ø±ÛŒØ§Ø¶ÛŒ", "science"],
            "ÙÙ†Ø§ÙˆØ±ÛŒ": ["ØªÚ©Ù†ÙˆÙ„ÙˆÚ˜ÛŒ", "ÙÙ†Ø§ÙˆØ±ÛŒ", "technology", "Ú©Ø§Ù…Ù¾ÛŒÙˆØªØ±"],
            "Ø³Ù„Ø§Ù…Øª": ["Ø³Ù„Ø§Ù…Øª", "Ù¾Ø²Ø´Ú©ÛŒ", "Ø¯Ø±Ù…Ø§Ù†", "Ø¨ÛŒÙ…Ø§Ø±ÛŒ", "health"]
        }
        
        combined_text = f"{message} {response}".lower()
        
        for topic, keywords in topic_keywords.items():
            if any(keyword in combined_text for keyword in keywords):
                self.add_context(
                    content=f"Ø¨Ø­Ø« Ø¯Ø±Ø¨Ø§Ø±Ù‡ {topic}: {message[:100]}...",
                    context_type=ContextType.TOPIC,
                    importance=ContextImportance.HIGH,
                    metadata={"topic": topic, "keywords": keywords}
                )
                break
    
    def _manage_context_size(self):
        """Ù…Ø¯ÛŒØ±ÛŒØª Ø§Ù†Ø¯Ø§Ø²Ù‡ context Ù‡Ø§"""
        if len(self.contexts) > self.max_contexts:
            # Ø­Ø°Ù Ù‚Ø¯ÛŒÙ…ÛŒâ€ŒØªØ±ÛŒÙ† context Ù‡Ø§
            sorted_contexts = sorted(
                self.contexts.items(),
                key=lambda x: (x[1].importance.value, x[1].timestamp),
                reverse=True
            )
            
            # Ù†Ú¯Ù‡â€ŒØ¯Ø§Ø±ÛŒ Ù…Ù‡Ù…â€ŒØªØ±ÛŒÙ† context Ù‡Ø§
            keep_count = int(self.max_contexts * 0.8)
            contexts_to_keep = dict(sorted_contexts[:keep_count])
            
            # Ø­Ø°Ù context Ù‡Ø§ÛŒ Ø§Ø¶Ø§ÙÛŒ
            removed_count = len(self.contexts) - len(contexts_to_keep)
            self.contexts = contexts_to_keep
            
            # Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ù„ÛŒØ³Øªâ€ŒÙ‡Ø§ÛŒ Ù…Ø±ØªØ¨Ø·
            self._cleanup_context_references()
            
            print(f"ðŸ—‘ï¸ {removed_count} context Ù‚Ø¯ÛŒÙ…ÛŒ Ø­Ø°Ù Ø´Ø¯")
    
    def _cleanup_context_references(self):
        """Ù¾Ø§Ú©â€ŒØ³Ø§Ø²ÛŒ Ø§Ø±Ø¬Ø§Ø¹Ø§Øª context Ù‡Ø§ÛŒ Ø­Ø°Ù Ø´Ø¯Ù‡"""
        valid_ids = set(self.contexts.keys())
        
        # Ù¾Ø§Ú©â€ŒØ³Ø§Ø²ÛŒ context_history
        self.context_history = [
            ctx_id for ctx_id in self.context_history 
            if ctx_id in valid_ids
        ]
        
        # Ù¾Ø§Ú©â€ŒØ³Ø§Ø²ÛŒ active_contexts
        self.active_contexts = [
            ctx_id for ctx_id in self.active_contexts 
            if ctx_id in valid_ids
        ]
        
        # Ù¾Ø§Ú©â€ŒØ³Ø§Ø²ÛŒ topic_contexts
        for topic in list(self.topic_contexts.keys()):
            self.topic_contexts[topic] = [
                ctx_id for ctx_id in self.topic_contexts[topic]
                if ctx_id in valid_ids
            ]
            
            # Ø­Ø°Ù topic Ù‡Ø§ÛŒ Ø®Ø§Ù„ÛŒ
            if not self.topic_contexts[topic]:
                del self.topic_contexts[topic]
    
    def get_context_summary(self) -> Dict:
        """Ø®Ù„Ø§ØµÙ‡ ÙˆØ¶Ø¹ÛŒØª context Ù‡Ø§"""
        now = datetime.now()
        
        # Ø´Ù…Ø§Ø±Ø´ context Ù‡Ø§ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù†ÙˆØ¹
        type_counts = defaultdict(int)
        expired_count = 0
        
        for context in self.contexts.values():
            type_counts[context.type.value] += 1
            if context.expires_at and now > context.expires_at:
                expired_count += 1
        
        return {
            "total_contexts": len(self.contexts),
            "active_contexts": len(self.active_contexts),
            "expired_contexts": expired_count,
            "contexts_by_type": dict(type_counts),
            "topics": list(self.topic_contexts.keys()),
            "memory_usage": f"{len(self.contexts)} / {self.max_contexts}"
        }

# Instance Ø³Ø±Ø§Ø³Ø±ÛŒ
context_manager = ContextManager()