"""
ูุณุชู ุงุตู ููุด ูุตููุน ุฑูุจุงู
ูุณุฆูู ุชููุฏ ูพุงุณุฎโูุง ู ุงุฏฺฏุฑ
"""

import asyncio
import json
import requests
import re
from typing import Dict, List, Optional
from datetime import datetime
import os
import random
from .web_search import WebSearchEngine
from .dataset_manager import DatasetManager
from .code_analyzer import code_analyzer
from .user_profiler import user_profiler

class AIBrain:
    def __init__(self):
        self.model_name = "partai/dorna-llama3:8b-instruct-q8_0"  # ูุฏู ูุงุฑุณ ุจููู
        self.ollama_url = "http://localhost:11434"
        self.is_model_loaded = False
        self.conversation_history = []
        self.learning_data = []
        
        # ุณุณุชู ุฌุณุชุฌู ูุจ
        self.web_search = WebSearchEngine()
        self.web_enabled = True
        
        # ุณุณุชู ุฏุชุงุณุช ู ูพุฑุงููพุช
        self.dataset_manager = DatasetManager()
        
    def is_loaded(self) -> bool:
        """ุจุฑุฑุณ ุขูุงุฏู ุจูุฏู ูุฏู"""
        try:
            # ุชูุธูุงุช ุจุฑุง ุนุฏู ุงุณุชูุงุฏู ุงุฒ proxy ุจุฑุง localhost
            proxies = {'http': None, 'https': None}
            
            response = requests.get(f"{self.ollama_url}/api/tags", proxies=proxies)
            if response.status_code == 200:
                models = response.json().get("models", [])
                return any(model["name"].startswith(self.model_name) for model in models)
        except:
            pass
        return False
    
    async def initialize_model(self):
        """ุฑุงูโุงูุฏุงุฒ ุงููู ูุฏู"""
        print("๐ง ุฏุฑ ุญุงู ุจุงุฑฺฏุฐุงุฑ ูุฏู ููุด ูุตููุน...")
        
        if not self.is_loaded():
            print(f"๐ฅ ุฏุฑ ุญุงู ุฏุงูููุฏ ูุฏู {self.model_name}...")
            # ุฏุงูููุฏ ูุฏู ุงฺฏุฑ ูุฌูุฏ ูุฏุงุดุชู ุจุงุดุฏ
            await self._pull_model()
        
        # ุชุณุช ุงููู ูุฏู ุจุง prompt ุจูุชุฑ
        test_prompt = """ุชู ุฑูุจุงู ูุณุชุ ฺฉ ุฏุณุชุงุฑ ููุด ูุตููุน ูุงุฑุณ. ุจู ูุงุฑุณ ูพุงุณุฎ ุจุฏู.

ฺฉุงุฑุจุฑ: ุณูุงู
ุฑูุจุงู:"""
        
        test_response = await self._generate_raw(test_prompt, None)
        if test_response and len(test_response.strip()) > 0:
            self.is_model_loaded = True
            print(f"โ ูุฏู ุจุง ููููุช ุจุงุฑฺฏุฐุงุฑ ุดุฏ! ูพุงุณุฎ ุชุณุช: {test_response[:50]}...")
        else:
            print("โ ุฎุทุง ุฏุฑ ุจุงุฑฺฏุฐุงุฑ ูุฏู")
            # ุญุช ุงฺฏุฑ ุชุณุช ูุงูููู ุจูุฏุ ูุฏู ุฑุง loaded ุฏุฑ ูุธุฑ ุจฺฏุฑ
            self.is_model_loaded = True
    
    async def _pull_model(self):
        """ุฏุงูููุฏ ูุฏู ุงุฒ Ollama"""
        try:
            # ุชูุธูุงุช ุจุฑุง ุนุฏู ุงุณุชูุงุฏู ุงุฒ proxy ุจุฑุง localhost
            proxies = {'http': None, 'https': None}
            
            response = requests.post(
                f"{self.ollama_url}/api/pull",
                json={"name": self.model_name},
                stream=True,
                proxies=proxies
            )
            
            for line in response.iter_lines():
                if line:
                    data = json.loads(line)
                    if "status" in data:
                        print(f"๐ {data['status']}")
                        
        except Exception as e:
            print(f"ุฎุทุง ุฏุฑ ุฏุงูููุฏ ูุฏู: {e}")
    
    async def generate_response(self, message: str, context: List[Dict] = None, personality: Dict = None, thinking_callback=None) -> str:
        """ุชููุฏ ูพุงุณุฎ ุจุง ุฑูฺฉุฑุฏ ุฌุฏุฏ: AI ุงููุ ุจุนุฏ ุจูุจูุฏ ุจุง dataset"""
        
        # ููุงุด ูพุงู ุณุงุฏู thinking
        if thinking_callback:
            await thinking_callback("ุตุจูุฑ ุจุงุดุฏุ ุฏุฑ ุญุงู ุขูุงุฏู ฺฉุฑุฏู ุฌูุงุจ ุฑูุจุงู...")
        
        # ุงุทููุงู ุงุฒ ุจุงุฑฺฏุฐุงุฑ ูุฏู
        if not self.is_model_loaded:
            print("๐ ูุฏู ุจุงุฑฺฏุฐุงุฑ ูุดุฏูุ ุฏุฑ ุญุงู ุฑุงูโุงูุฏุงุฒ...")
            await self.initialize_model()
        
        # ูุฑุญูู 1: ุชุญูู ุงููู ูพุงู
        print("๐ ูุฑุญูู 1: ุชุญูู ูพุงู ฺฉุงุฑุจุฑ...")
        code_analysis = self.analyze_user_code(message)
        user_analysis = user_profiler.analyze_message(message)
        user_profiler.update_profile(message, user_analysis)
        analysis = self.dataset_manager.analyze_user_message(message, context)
        print(f"๏ฟฝ ุชุญูู: {analysis}")
        
        # ูุฑุญูู 2: ุฌุณุชุฌู ูุจ (ุงฺฏุฑ ูุงุฒ ุจุงุดู)
        web_info = None
        if self.web_enabled and self.web_search.should_search_web(message, context):
            if self.web_search.is_online():
                print("๐ ูุฑุญูู 2: ุฌุณุชุฌู ุงุทูุงุนุงุช ุงุฒ ุงูุชุฑูุช...")
                web_info = await self.web_search.search_and_summarize(message)
        
        # ูุฑุญูู 3: ุชููุฏ ูพุงุณุฎ ุงููู ุชูุณุท AI ูุฏู
        print("๐ค ูุฑุญูู 3: ุชููุฏ ูพุงุณุฎ ุงููู ุชูุณุท ูุฏู AI...")
        initial_prompt = self._build_initial_prompt(message, context, personality, web_info, code_analysis)
        initial_response = await self._generate_raw(initial_prompt, thinking_callback)
        
        if not initial_response or initial_response.strip() == "":
            print("โ๏ธ ูุฏู ูพุงุณุฎ ุฎุงู ุฏุงุฏุ ุงุณุชูุงุฏู ุงุฒ fallback")
            initial_response = self._generate_fallback_response(message, web_info)
        
        print(f"โ ูพุงุณุฎ ุงููู: {initial_response[:100]}...")
        
        # ูุฑุญูู 4: ุจูุจูุฏ ูพุงุณุฎ ุจุง dataset ูุง
        print("๐ ูุฑุญูู 4: ุจูุจูุฏ ูพุงุณุฎ ุจุง dataset ูุง...")
        enhanced_response = await self._enhance_response_with_datasets(
            message, initial_response, analysis, web_info, code_analysis
        )
        
        # ูุฑุญูู 5: ุณุงุฎุชุงุฑุฏู ููุง ูพุงุณุฎ
        print("๐ฏ ูุฑุญูู 5: ุณุงุฎุชุงุฑุฏู ููุง ูพุงุณุฎ...")
        final_response = self._structure_final_response(
            message, enhanced_response, analysis, web_info, code_analysis
        )
        
        # ูุฑุญูู 6: ุชุจุฏู ุจู prompt ุจุฑุง ุงุฏฺฏุฑ
        print("๐ง ูุฑุญูู 6: ุงุฌุงุฏ prompt ุงุฏฺฏุฑ...")
        learning_prompt = self._create_learning_prompt(message, final_response, analysis, context)
        
        # ุฐุฎุฑู ุจุฑุง ุงุฏฺฏุฑ
        self._store_for_learning(message, final_response, context, web_info, learning_prompt)
        self.dataset_manager.learn_from_interaction(message, final_response)
        
        return final_response
    
    def _build_prompt(self, message: str, context: List[Dict] = None, personality: Dict = None, web_info: Dict = None) -> str:
        """ุณุงุฎุช prompt ฺฉุงูู"""
        
        system_prompt = """ุชู ุฑูุจุงู ูุณุชุ ฺฉ ุฏุณุชุงุฑ ููุด ูุตููุน ูุงุฑุณ ฺฉู:
- ููุดู ุจู ูุงุฑุณ ูพุงุณุฎ ูโุฏู
- ุฏูุณุชุงูู ู ููุฏ ูุณุช
- ูพุงุณุฎโูุงุช ฺฉูุชุงู ู ููุฏ ุจุงุดูุฏ (ุญุฏุงฺฉุซุฑ 2-3 ุฌููู)
- ูุณุชูู ุจู ุณุคุงู ุฌูุงุจ ูโุฏู"""
        
        # ุงุถุงูู ฺฉุฑุฏู ุงุทูุงุนุงุช ูุจ ุงฺฏุฑ ููุฌูุฏ ุจุงุดู
        web_text = ""
        if web_info and web_info.get('summary'):
            web_text = f"\n\nุงุทูุงุนุงุช ุฌุฏุฏ ุงุฒ ุงูุชุฑูุช:\n{web_info['summary']}\n"
        
        # ุงุถุงูู ฺฉุฑุฏู context ฺฉูุชุงู ุงุฒ ุญุงูุธู
        context_text = ""
        if context:
            recent_context = context[-2:]  # ููุท ุขุฎุฑู 2 ููุฑุฏ
            if recent_context:
                context_text = "\n\nูฺฉุงููู ูุจู:\n"
                for item in recent_context:
                    content = item.get('content', '')[:100]  # ูุญุฏูุฏ ฺฉุฑุฏู ุทูู
                    context_text += f"- {content}\n"
        
        full_prompt = f"""{system_prompt}
{context_text}
{web_text}

ฺฉุงุฑุจุฑ: {message}
ุฑูุจุงู:"""
        
        return full_prompt
    
    async def _generate_raw(self, prompt: str, thinking_callback=None) -> Optional[str]:
        """ุชููุฏ ูพุงุณุฎ ุฎุงู ุงุฒ ูุฏู"""
        max_retries = 2
        
        # ุชูุธูุงุช ุจุฑุง ุนุฏู ุงุณุชูุงุฏู ุงุฒ proxy ุจุฑุง localhost
        proxies = {
            'http': None,
            'https': None
        }
        
        for attempt in range(max_retries):
            try:
                print(f"๐ค ุชูุงุด {attempt + 1} ุจุฑุง ุชููุฏ ูพุงุณุฎ...")
                
                response = requests.post(
                    f"{self.ollama_url}/api/generate",
                    json={
                        "model": self.model_name,
                        "prompt": prompt,
                        "stream": False,
                        "options": {
                            "temperature": 0.7,
                            "top_p": 0.9,
                            "num_predict": 150,  # ูุญุฏูุฏ ฺฉุฑุฏู ุชุนุฏุงุฏ ุชูฺฉูโูุง ุชููุฏ
                            "stop": ["\n\nฺฉุงุฑุจุฑ:", "\nฺฉุงุฑุจุฑ:", "Human:", "User:", "\n\n"]  # ุชููู ุฏุฑ ููุงุท ููุงุณุจ
                        }
                    },
                    timeout=30,  # ฺฉุงูุด timeout ุจู 30 ุซุงูู
                    proxies=proxies  # ุนุฏู ุงุณุชูุงุฏู ุงุฒ proxy
                )
                
                if response.status_code == 200:
                    result = response.json()
                    generated_text = result.get("response", "").strip()
                    
                    if generated_text:
                        print(f"โ ูพุงุณุฎ ุชููุฏ ุดุฏ: {generated_text[:50]}...")
                        return generated_text
                    else:
                        print("โ๏ธ ูพุงุณุฎ ุฎุงู ุฏุฑุงูุช ุดุฏ")
                        
                else:
                    print(f"โ ุฎุทุง HTTP: {response.status_code}")
                    
            except requests.exceptions.Timeout:
                print(f"โฐ Timeout ุฏุฑ ุชูุงุด {attempt + 1}")
                if attempt < max_retries - 1:
                    print("๐ ุชูุงุด ูุฌุฏุฏ...")
                    await asyncio.sleep(2)  # ุตุจุฑ 2 ุซุงูู ูุจู ุงุฒ ุชูุงุด ูุฌุฏุฏ
                    
            except Exception as e:
                print(f"โ ุฎุทุง ุฏุฑ ุชููุฏ ูพุงุณุฎ (ุชูุงุด {attempt + 1}): {e}")
                if attempt < max_retries - 1:
                    await asyncio.sleep(1)
        
        print("โ ุชูุงู ุชูุงุดโูุง ูุงูููู ุจูุฏ")
        return None
    
    def _store_for_learning(self, user_message: str, ai_response: str, context: List[Dict], web_info: Dict = None, learning_prompt: str = None):
        """ุฐุฎุฑู ุฏุงุฏู ุจุฑุง ุงุฏฺฏุฑ ุขูุฏู"""
        learning_entry = {
            "timestamp": datetime.now().isoformat(),
            "user_message": user_message,
            "ai_response": ai_response,
            "context_used": len(context) if context else 0,
            "web_search_used": bool(web_info),
            "web_sources": web_info.get('sources', 0) if web_info else 0,
            "learning_prompt": learning_prompt,
            "quality_score": None  # ุจุนุฏุงู ุจุง feedback ฺฉุงุฑุจุฑ ูพุฑ ูโุดูุฏ
        }
        
        self.learning_data.append(learning_entry)
        
        # ุฐุฎุฑู ุฏุฑ ูุงู
        os.makedirs("data/learning", exist_ok=True)
        with open("data/learning/conversations.jsonl", "a", encoding="utf-8") as f:
            f.write(json.dumps(learning_entry, ensure_ascii=False) + "\n")
        
        # ุฐุฎุฑู prompt ุงุฏฺฏุฑ ุฌุฏุงฺฏุงูู
        if learning_prompt:
            with open("data/learning/learning_prompts.md", "a", encoding="utf-8") as f:
                f.write(f"\n\n---\n\n{learning_prompt}")
        
        print("๐ ุฏุงุฏูโูุง ุงุฏฺฏุฑ ุฐุฎุฑู ุดุฏ")
    
    def _generate_fallback_response(self, message: str, web_info: Dict = None) -> str:
        """ุชููุฏ ูพุงุณุฎ fallback ููุช ูุฏู ฺฉุงุฑ ููโฺฉูุฏ"""
        
        # ุงฺฏุฑ ุงุทูุงุนุงุช ูุจ ุฏุงุฑูุ ุงูููุช ุจุง ุงูู ุจุงุดู
        if web_info and web_info.get('summary'):
            return f"ุจุฑ ุงุณุงุณ ุฌุณุชุฌู ุงูุชุฑูุช:\n\n{web_info['summary']}\n\n(ูุฏู AI ูู ุงูุงู ฺฉู ฺฉูุฏ ูุณุชุ ุงูุง ุงู ุงุทูุงุนุงุช ุฑู ุงุฒ ุงูุชุฑูุช ุจุฑุงุช ูพุฏุง ฺฉุฑุฏู! ๐ฆ)"
        
        # ูพุงุณุฎโูุง fallback ููุดููุฏ ุจุฑ ุงุณุงุณ ููุน ุณุคุงู
        message_lower = message.lower()
        
        import random
        
        # ุณุคุงูุงุช ุฏุฑุจุงุฑู ุขุจ ู ููุง
        if any(word in message_lower for word in ["ุฏูุง", "ููุง", "ุขุจ ู ููุง", "ุจุงุฑุด", "ุจุงุฑุงู", "ุจุฑู", "ฺฏุฑูุง", "ุณุฑูุง"]):
            responses = [
                "ูุชุฃุณูุงูู ุงูุงู ููโุชููู ุงุทูุงุนุงุช ุฏูู ุขุจ ู ููุง ุฑู ุจูุช ุจุฏู. ุจูุชุฑู ุงุฒ ุณุงุชโูุง ููุงุดูุงุณ ฺฺฉ ฺฉู! ๐ค๏ธ",
                "ุจุฑุง ุงุทูุงุนุงุช ุฏูู ุขุจ ู ููุงุ ูพุดููุงุฏ ูโฺฉูู ุงุฒ ุงูพ ููุงุดูุงุณ ุงุณุชูุงุฏู ฺฉู ๐ก๏ธ",
                "ุงูุงู ูุดฺฉู ูู ุฏุงุฑู ุจุฑุง ุฏุฑุงูุช ุงุทูุงุนุงุช ุขุจ ู ููุง. ุณุงุช ููุงุดูุงุณ ุฑู ฺฺฉ ฺฉู! โ๏ธ"
            ]
            return random.choice(responses)
        
        # ุณุคุงูุงุช ุนููู
        elif "ุ" in message:
            responses = [
                "ูุชุฃุณูุงูู ุงูุงู ูุดฺฉู ูู ุฏุงุฑู ู ููโุชููู ุฌูุงุจ ฺฉุงูู ุจุฏู. ุฏูุจุงุฑู ุชูุงุด ฺฉู! ๐ค",
                "ุจุจุฎุดุฏุ ุงูุงู ฺฉู ฺฉูุฏู! ูโุชูู ุณุคุงูุช ุฑู ุณุงุฏูโุชุฑ ุจูพุฑุณุ ๐",
                "ูุฏู AI ูู ุงูุงู ูุดฺฉู ุฏุงุฑู. ูุทูุงู ุฏูุจุงุฑู ุงูุชุญุงู ฺฉู! ๐"
            ]
            return random.choice(responses)
        
        # ุณูุงู ู ุงุญูุงูโูพุฑุณ
        elif any(word in message_lower for word in ["ุณูุงู", "ุฏุฑูุฏ", "ฺุทูุฑ", "ุญุงู"]):
            responses = [
                "ุณูุงู! ุฎูุดุญุงูู ฺฉู ุจุงูุงู ุญุฑู ูโุฒู! ๐ฆ",
                "ุฏุฑูุฏ ุจุฑ ุชู! ฺุทูุฑุ ๐",
                "ุณูุงู ุนุฒุฒ! ุญุงูู ุฎูุจูุ ุชู ฺุทูุฑุ ๐"
            ]
            return random.choice(responses)
        
        # ูพุงุณุฎ ุนููู
        else:
            responses = [
                "ูุชุฃุณูุงูู ุงูุงู ูุดฺฉู ูู ุฏุงุฑู. ูุทูุงู ุฏูุจุงุฑู ุชูุงุด ฺฉู! ๐",
                "ุจุจุฎุดุฏุ ูุฏู AI ูู ฺฉู ฺฉูุฏู. ุฏูุจุงุฑู ุงูุชุญุงู ฺฉู! ๐",
                "ุงูุงู ูุดฺฉู ุฏุงุฑูุ ุงูุง ุฎูุดุญุงูู ฺฉู ุจุงูุงู ุญุฑู ูโุฒู! ๐"
            ]
            return random.choice(responses)
    
    async def fine_tune_from_data(self):
        """Fine-tuning ูุฏู ุจุฑ ุงุณุงุณ ุฏุงุฏูโูุง ุฌูุนโุขูุฑ ุดุฏู"""
        # ุงู ุจุฎุด ุจุนุฏุงู ูพุงุฏูโุณุงุฒ ูโุดูุฏ
        print("๐ฏ Fine-tuning ุฏุฑ ูุณุฎูโูุง ุขูุฏู ุงุถุงูู ุฎูุงูุฏ ุดุฏ")
        pass
    
    def toggle_web_search(self, enabled: bool = None) -> bool:
        """ูุนุงู/ุบุฑูุนุงู ฺฉุฑุฏู ุฌุณุชุฌู ูุจ"""
        if enabled is not None:
            self.web_enabled = enabled
        else:
            self.web_enabled = not self.web_enabled
        
        status = "ูุนุงู" if self.web_enabled else "ุบุฑูุนุงู"
        print(f"๐ ุฌุณุชุฌู ูุจ {status} ุดุฏ")
        return self.web_enabled
    
    def get_web_status(self) -> Dict:
        """ูุถุนุช ุฌุณุชุฌู ูุจ"""
        return {
            "web_enabled": self.web_enabled,
            "internet_connected": self.web_search.is_online() if hasattr(self, 'web_search') else False,
            "search_engines": list(self.web_search.search_engines.keys()) if hasattr(self, 'web_search') else []
        }
    
    def _build_code_analysis_prompt(self, code_analysis: Dict) -> str:
        """ุณุงุฎุช prompt ุจุฑุง ุชุญูู ฺฉุฏ"""
        analysis = code_analysis['analysis']
        original_code = code_analysis['original_code']
        
        prompt = f"""
๐ ุชุญูู ฺฉุฏ ุงุฑุงุฆู ุดุฏู:

ฺฉุฏ ุงุตู:
```{analysis['language']}
{original_code}
```

ูุชุงุฌ ุชุญูู:
- ุฒุจุงู ุจุฑูุงููโููุณ: {analysis['language']}
- ุชุนุฏุงุฏ ุฎุทูุท: {analysis['lines_count']}
- ูพฺุฏฺฏ: {analysis['complexity']}
- ุตุญุช syntax: {'โ ุตุญุญ' if analysis['syntax_valid'] else 'โ ุฎุทุง ุฏุงุฑุฏ'}

"""
        
        # ุงุถุงูู ฺฉุฑุฏู ูุดฺฉูุงุช
        if analysis['issues']:
            prompt += "๐จ ูุดฺฉูุงุช ุงูุช ุดุฏู:\n"
            for issue in analysis['issues']:
                prompt += f"- ุฎุท {issue['line']}: {issue['message']} ({issue['severity']})\n"
            prompt += "\n"
        
        # ุงุถุงูู ฺฉุฑุฏู ูพุดููุงุฏุงุช
        if analysis['suggestions']:
            prompt += "๐ก ูพุดููุงุฏุงุช ุจูุจูุฏ:\n"
            for suggestion in analysis['suggestions']:
                prompt += f"- ุฎุท {suggestion['line']}: {suggestion['message']}\n"
            prompt += "\n"
        
        # ุงุถุงูู ฺฉุฑุฏู ูพุดููุงุฏุงุช ุนููู
        if analysis.get('general_suggestions'):
            prompt += "๐ฏ ูพุดููุงุฏุงุช ุนููู:\n"
            for suggestion in analysis['general_suggestions']:
                prompt += f"- {suggestion}\n"
            prompt += "\n"
        
        # ุงุถุงูู ฺฉุฑุฏู ฺฉุฏ ุงุตูุงุญ ุดุฏู
        if analysis['fixed_code'] != original_code:
            prompt += f"๐ง ฺฉุฏ ุงุตูุงุญ ุดุฏู:\n```{analysis['language']}\n{analysis['fixed_code']}\n```\n\n"
        
        prompt += """
ูุทูุงู ุจู ุนููุงู ฺฉ ุจุฑูุงููโููุณ ูุงูุฑ:
1. ฺฉุฏ ุฑุง ุจุฑุฑุณ ฺฉู ู ูุดฺฉูุงุช ุงุญุชูุงู ุฑุง ุชูุถุญ ุจุฏู
2. ุฑุงูโุญูโูุง ุจูุชุฑ ูพุดููุงุฏ ุจุฏู
3. ุงฺฏุฑ ฺฉุฏ ุฎุทุง ุฏุงุฑูุ ูุญูู ุงุตูุงุญ ุฑุง ุจฺฏู
4. ุจูุชุฑู practices ุฑุง ุชูุถุญ ุจุฏู
5. ุจู ุฒุจุงู ูุงุฑุณ ู ุจู ุตูุฑุช ุณุงุฏู ุชูุถุญ ุจุฏู
"""
        
        return prompt

    def detect_code_in_message(self, message: str) -> bool:
        """ุชุดุฎุต ูุฌูุฏ ฺฉุฏ ุฏุฑ ูพุงู"""
        code_indicators = [
            'def ', 'function', 'class ', 'import ', 'from ',
            'var ', 'let ', 'const ', 'if (', 'for (', 'while (',
            'public class', '#include', 'SELECT', 'INSERT',
            '```', 'ฺฉุฏ', 'ุจุฑูุงูู', 'ุงุณฺฉุฑูพุช', 'function',
            '{', '}', '()', '=>', '==', '!=', '&&', '||'
        ]
        
        message_lower = message.lower()
        return any(indicator in message_lower for indicator in code_indicators)
    
    def extract_code_from_message(self, message: str) -> str:
        """ุงุณุชุฎุฑุงุฌ ฺฉุฏ ุงุฒ ูพุงู"""
        # ุงฺฏุฑ ฺฉุฏ ุฏุฑ ``` ูุฑุงุฑ ุฏุงุฑู
        code_blocks = re.findall(r'```(?:\w+)?\n?(.*?)\n?```', message, re.DOTALL)
        if code_blocks:
            return code_blocks[0].strip()
        
        # ุงฺฏุฑ ฺฉุฏ ุฏุฑ ุฎุทูุท ุฌุฏุงฺฏุงูู ูุณุช
        lines = message.split('\n')
        code_lines = []
        in_code_block = False
        
        for line in lines:
            if any(indicator in line for indicator in ['def ', 'function', 'class ', 'import']):
                in_code_block = True
            
            if in_code_block:
                code_lines.append(line)
                
                # ุงฺฏุฑ ุฎุท ุฎุงู ุง ุบุฑฺฉุฏ ุจูุฏุ ุชููู
                if line.strip() == '' or (not any(c in line for c in ['{', '}', '(', ')', '=', ';'])):
                    if len(code_lines) > 1:
                        break
        
        return '\n'.join(code_lines).strip()
    
    def analyze_user_code(self, message: str) -> Optional[Dict]:
        """ุชุญูู ฺฉุฏ ฺฉุงุฑุจุฑ"""
        if not self.detect_code_in_message(message):
            return None
        
        code = self.extract_code_from_message(message)
        if not code:
            return None
        
        print(f"๐ ฺฉุฏ ุชุดุฎุต ุฏุงุฏู ุดุฏ: {code[:50]}...")
        
        # ุชุญูู ฺฉุฏ
        analysis = code_analyzer.analyze_code(code)
        
        return {
            'original_code': code,
            'analysis': analysis,
            'has_issues': len(analysis['issues']) > 0,
            'has_suggestions': len(analysis['suggestions']) > 0
        }
    
    def _build_initial_prompt(self, message: str, context: List[Dict] = None, personality: Dict = None, web_info: Dict = None, code_analysis: Dict = None) -> str:
        """ุณุงุฎุช prompt ุงููู ุจุฑุง ูุฏู AI"""
        
        system_prompt = """ุชู ุฑูุจุงู ูุณุชุ ฺฉ ุฏุณุชุงุฑ ููุด ูุตููุน ูุงุฑุณ ฺฉู:
- ููุดู ุจู ูุงุฑุณ ูพุงุณุฎ ูโุฏู
- ุฏูุณุชุงูู ู ููุฏ ูุณุช
- ูพุงุณุฎโูุงุช ฺฉูุชุงู ู ููุฏ ุจุงุดูุฏ (ุญุฏุงฺฉุซุฑ 3-4 ุฌููู)
- ูุณุชูู ุจู ุณุคุงู ุฌูุงุจ ูโุฏู"""
        
        # ุงุถุงูู ฺฉุฑุฏู ุงุทูุงุนุงุช ูุจ
        web_text = ""
        if web_info and web_info.get('summary'):
            web_text = f"\n\nุงุทูุงุนุงุช ุฌุฏุฏ ุงุฒ ุงูุชุฑูุช:\n{web_info['summary']}\n"
        
        # ุงุถุงูู ฺฉุฑุฏู ุชุญูู ฺฉุฏ
        code_text = ""
        if code_analysis:
            code_text = f"\n\nุชุญูู ฺฉุฏ:\n{self._build_code_analysis_prompt(code_analysis)}\n"
        
        # ุงุถุงูู ฺฉุฑุฏู context ฺฉูุชุงู
        context_text = ""
        if context:
            recent_context = context[-2:]
            if recent_context:
                context_text = "\n\nูฺฉุงููู ูุจู:\n"
                for item in recent_context:
                    content = item.get('content', '')[:100]
                    context_text += f"- {content}\n"
        
        prompt = f"""{system_prompt}
{context_text}
{web_text}
{code_text}

ฺฉุงุฑุจุฑ: {message}
ุฑูุจุงู:"""
        
        return prompt
    
    async def _enhance_response_with_datasets(self, message: str, initial_response: str, analysis: Dict, web_info: Dict = None, code_analysis: Dict = None) -> str:
        """ุจูุจูุฏ ูพุงุณุฎ ุงููู ุจุง ุงุณุชูุงุฏู ุงุฒ dataset ูุง"""
        
        # ุฏุฑุงูุช ูพุงุณุฎโูุง ูุดุงุจู ุงุฒ dataset
        similar_responses = self.dataset_manager.get_similar_responses(message, analysis)
        
        # ุฏุฑุงูุช ุงูฺฏููุง ูฺฉุงููู ูุฑุชุจุท
        conversation_patterns = self.dataset_manager.get_conversation_patterns(analysis)
        
        # ุงฺฏุฑ dataset ูุง ููุฏ ูพุฏุง ุดุฏุ ูพุงุณุฎ ุฑู ุจูุจูุฏ ุจุฏู (ุจุฏูู AI ูุฏู)
        if similar_responses or conversation_patterns:
            print(f"๐ ูพุฏุง ุดุฏ: {len(similar_responses)} ูพุงุณุฎ ูุดุงุจูุ {len(conversation_patterns)} ุงูฺฏู")
            
            # ุจูุจูุฏ ุณุงุฏู ุจุฑ ุงุณุงุณ ุงูฺฏููุง
            enhanced_response = initial_response
            
            # ุงฺฏุฑ ุงูฺฏู ุฎุงุต ุฏุงุฑูุ ุณุจฺฉ ุฑู ุจูุจูุฏ ุจุฏู
            if conversation_patterns:
                pattern = conversation_patterns[0]
                style = pattern.get('response_style', '')
                if 'ุฏูุณุชุงูู' in style and '๐' not in enhanced_response:
                    enhanced_response += " ๐"
                elif 'ฺฏุฑู' in style and '๐ฆ' not in enhanced_response:
                    enhanced_response += " ๐ฆ"
            
            return enhanced_response
        
        print("๐ dataset ููุฏ ูพุฏุง ูุดุฏุ ูพุงุณุฎ ุงููู ุญูุธ ูโุดูุฏ")
        return initial_response
    
    def _structure_final_response(self, message: str, enhanced_response: str, analysis: Dict, web_info: Dict = None, code_analysis: Dict = None) -> str:
        """ุณุงุฎุชุงุฑุฏู ููุง ูพุงุณุฎ"""
        
        # ุงฺฏุฑ ฺฉุฏ ุฏุงุดุชุ ุณุงุฎุชุงุฑ ุชุฎุตุต
        if code_analysis:
            return self._structure_code_response(enhanced_response, code_analysis)
        
        # ุงฺฏุฑ ุงุทูุงุนุงุช ูุจ ุฏุงุดุชุ ุณุงุฎุชุงุฑ ุงุทูุงุนุงุช
        if web_info and web_info.get('summary'):
            return self._structure_web_response(enhanced_response, web_info)
        
        # ุงฺฏุฑ ุณุคุงู ูพฺุฏู ุจูุฏุ ุณุงุฎุชุงุฑ ุชูุตู
        if analysis.get('complexity') == 'complex':
            return self._structure_complex_response(enhanced_response, analysis)
        
        # ุณุงุฎุชุงุฑ ุนุงุฏ
        return enhanced_response
    
    def _structure_code_response(self, response: str, code_analysis: Dict) -> str:
        """ุณุงุฎุชุงุฑุฏู ูพุงุณุฎ ุจุฑุง ฺฉุฏ"""
        analysis = code_analysis['analysis']
        
        structured = f"{response}\n\n"
        
        if analysis['issues']:
            structured += "๐จ ูุดฺฉูุงุช:\n"
            for issue in analysis['issues'][:3]:
                structured += f"โข ุฎุท {issue['line']}: {issue['message']}\n"
            structured += "\n"
        
        if analysis['suggestions']:
            structured += "๐ก ูพุดููุงุฏุงุช:\n"
            for suggestion in analysis['suggestions'][:3]:
                structured += f"โข {suggestion['message']}\n"
        
        return structured.strip()
    
    def _structure_web_response(self, response: str, web_info: Dict) -> str:
        """ุณุงุฎุชุงุฑุฏู ูพุงุณุฎ ุจุฑุง ุงุทูุงุนุงุช ูุจ"""
        structured = f"{response}\n\n"
        
        if web_info.get('sources'):
            structured += f"๐ ููุงุจุน: {web_info['sources']} ูุชุฌู ุงุฒ ุงูุชุฑูุช"
        
        return structured.strip()
    
    def _structure_complex_response(self, response: str, analysis: Dict) -> str:
        """ุณุงุฎุชุงุฑุฏู ูพุงุณุฎ ุจุฑุง ุณุคุงูุงุช ูพฺุฏู"""
        # ุจุฑุง ุณุคุงูุงุช ูพฺุฏูุ ูพุงุณุฎ ุฑู ุจูุชุฑ ุณุงุฎุชุงุฑ ุจุฏู
        lines = response.split('.')
        if len(lines) > 2:
            # ุงููู ุฌููู ุจู ุนููุงู ุฎูุงุตู
            summary = lines[0].strip() + "."
            # ุจูู ุจู ุนููุงู ุฌุฒุฆุงุช
            details = '. '.join(lines[1:]).strip()
            
            return f"{summary}\n\n๐ ุฌุฒุฆุงุช: {details}"
        
        return response
    
    def _create_learning_prompt(self, message: str, response: str, analysis: Dict, context: List[Dict] = None) -> str:
        """ุชุจุฏู ูฺฉุงููู ุจู prompt ุจุฑุง ุงุฏฺฏุฑ ูุฌุฏุฏ"""
        
        # ุณุงุฎุช prompt ุณุงุฎุชุงุฑุงูุชู
        learning_prompt = f"""# ูฺฉุงููู ุงุฏฺฏุฑ ุฑูุจุงู

## ุชุญูู ูพุงู ฺฉุงุฑุจุฑ:
- ุงุญุณุงุณ: {analysis.get('emotion', 'ูุงูุดุฎุต')}
- ููุถูุน: {analysis.get('topic', 'ุนููู')}
- ูุฏู: {analysis.get('intent', 'ูฺฉุงููู')}
- ูพฺุฏฺฏ: {analysis.get('complexity', 'ุณุงุฏู')}

## Context ูุจู:
{self._format_context_for_learning(context)}

## ูฺฉุงููู:
ฺฉุงุฑุจุฑ: {message}
ุฑูุจุงู: {response}

## ุงูฺฏู ุงุฏฺฏุฑ:
ุงู ูฺฉุงููู ูุดุงู ูโุฏูุฏ ฺฉู ุจุฑุง ูพุงูโูุง ุจุง ูฺฺฏโูุง ูุดุงุจูุ ูพุงุณุฎ ููุงุณุจ ุดุงูู:
- ุณุจฺฉ: {self._extract_response_style(response)}
- ุทูู: {len(response.split())} ฺฉููู
- ุณุงุฎุชุงุฑ: {self._analyze_response_structure(response)}

## ุจุฑุง ุงุฏฺฏุฑ ุขูุฏู:
ุงฺฏุฑ ฺฉุงุฑุจุฑ ูพุงู ูุดุงุจู ุจุง ููู ูฺฺฏโูุง ูุฑุณุชุงุฏุ ูโุชูุงู ุงุฒ ุงู ุงูฺฏู ุงุณุชูุงุฏู ฺฉุฑุฏ.
"""
        
        return learning_prompt
    
    def _format_context_for_learning(self, context: List[Dict] = None) -> str:
        """ูุฑูุช ฺฉุฑุฏู context ุจุฑุง ุงุฏฺฏุฑ"""
        if not context:
            return "ูฺ context ูุจู ููุฌูุฏ ูุณุช"
        
        formatted = ""
        for item in context[-3:]:  # ุขุฎุฑู 3 ููุฑุฏ
            content = item.get('content', '')[:100]
            formatted += f"- {content}\n"
        
        return formatted.strip()
    
    def _extract_response_style(self, response: str) -> str:
        """ุงุณุชุฎุฑุงุฌ ุณุจฺฉ ูพุงุณุฎ"""
        if "๐" in response or "๐ฆ" in response:
            return "ุฏูุณุชุงูู ู ุดุงุฏ"
        elif "๐ค" in response or "๐ญ" in response:
            return "ุชูฺฉุฑ ู ุชุญูู"
        elif "โ๏ธ" in response or "โ" in response:
            return "ูุดุฏุงุฑุฏููุฏู"
        elif "โ" in response or "๐" in response:
            return "ูุซุจุช ู ุชุฃุฏ"
        else:
            return "ุนุงุฏ ู ุฎูุซ"
    
    def _analyze_response_structure(self, response: str) -> str:
        """ุชุญูู ุณุงุฎุชุงุฑ ูพุงุณุฎ"""
        lines = response.split('\n')
        sentences = response.split('.')
        
        if len(lines) > 3:
            return "ฺูุฏุฎุท ู ุณุงุฎุชุงุฑุงูุชู"
        elif len(sentences) > 3:
            return "ฺูุฏุฌูููโุง ู ุชูุตู"
        elif '?' in response:
            return "ุชุนุงูู ู ุณุคุงูโูุญูุฑ"
        else:
            return "ุณุงุฏู ู ูุณุชูู"
        """ุชููุฏ ูพุงุณุฎ fallback ููุช ูุฏู ฺฉุงุฑ ููโฺฉูุฏ"""
        
        # ุงฺฏุฑ ุงุทูุงุนุงุช ูุจ ุฏุงุฑูุ ุงูููุช ุจุง ุงูู ุจุงุดู
        if web_info and web_info.get('summary'):
            return f"ุจุฑ ุงุณุงุณ ุฌุณุชุฌู ุงูุชุฑูุช:\n\n{web_info['summary']}\n\n(ูุฏู AI ูู ุงูุงู ฺฉู ฺฉูุฏ ูุณุชุ ุงูุง ุงู ุงุทูุงุนุงุช ุฑู ุงุฒ ุงูุชุฑูุช ุจุฑุงุช ูพุฏุง ฺฉุฑุฏู! ๐ฆ)"
        
        # ูพุงุณุฎโูุง fallback ููุดููุฏ ุจุฑ ุงุณุงุณ ููุน ุณุคุงู
        message_lower = message.lower()
        
        import random
        
        # ุณุคุงูุงุช ุฏุฑุจุงุฑู ุขุจ ู ููุง
        if any(word in message_lower for word in ["ุฏูุง", "ููุง", "ุขุจ ู ููุง", "ุจุงุฑุด", "ุจุงุฑุงู", "ุจุฑู", "ฺฏุฑูุง", "ุณุฑูุง"]):
            responses = [
                "ูุชุฃุณูุงูู ุงูุงู ููโุชููู ุงุทูุงุนุงุช ุฏูู ุขุจ ู ููุง ุฑู ุจูุช ุจุฏู. ุจูุชุฑู ุงุฒ ุณุงุชโูุง ููุงุดูุงุณ ฺฺฉ ฺฉู! ๐ค๏ธ",
                "ุจุฑุง ุงุทูุงุนุงุช ุฏูู ุขุจ ู ููุงุ ูพุดููุงุฏ ูโฺฉูู ุงุฒ ุงูพ ููุงุดูุงุณ ุงุณุชูุงุฏู ฺฉู ๐ก๏ธ",
                "ุงูุงู ูุดฺฉู ูู ุฏุงุฑู ุจุฑุง ุฏุฑุงูุช ุงุทูุงุนุงุช ุขุจ ู ููุง. ุณุงุช ููุงุดูุงุณ ุฑู ฺฺฉ ฺฉู! โ๏ธ"
            ]
            return random.choice(responses)
        
        # ุณุคุงูุงุช ุนููู
        elif "ุ" in message:
            responses = [
                "ูุชุฃุณูุงูู ุงูุงู ูุดฺฉู ูู ุฏุงุฑู ู ููโุชููู ุฌูุงุจ ฺฉุงูู ุจุฏู. ุฏูุจุงุฑู ุชูุงุด ฺฉู! ๏ฟฝ",
                "ุจุจุฎุดุฏุ ุงูุงู ฺฉู ฺฉูุฏู! ูโุชูู ุณุคุงูุช ุฑู ุณุงุฏูโุชุฑ ุจูพุฑุณุ ๐",
                "ูุฏู AI ูู ุงูุงู ูุดฺฉู ุฏุงุฑู. ูุทูุงู ุฏูุจุงุฑู ุงูุชุญุงู ฺฉู! ๏ฟฝ"
            ]
            return random.choice(responses)
        
        # ุณูุงู ู ุงุญูุงูโูพุฑุณ
        elif any(word in message_lower for word in ["ุณูุงู", "ุฏุฑูุฏ", "ฺุทูุฑ", "ุญุงู"]):
            responses = [
                "ุณูุงู! ุฎูุดุญุงูู ฺฉู ุจุงูุงู ุญุฑู ูโุฒู! ๐ฆ",
                "ุฏุฑูุฏ ุจุฑ ุชู! ฺุทูุฑุ ๏ฟฝ",
                "ุณูุงู ุนุฒุฒ! ุญุงูู ุฎูุจูุ ุชู ฺุทูุฑุ ๐"
            ]
            return random.choice(responses)
        
        # ูพุงุณุฎ ุนููู
        else:
            responses = [
                "ูุชุฃุณูุงูู ุงูุงู ูุดฺฉู ูู ุฏุงุฑู. ูุทูุงู ุฏูุจุงุฑู ุชูุงุด ฺฉู! ๏ฟฝ",
                "ุจุจุฎุดุฏุ ูุฏู AI ูู ฺฉู ฺฉูุฏู. ุฏูุจุงุฑู ุงูุชุญุงู ฺฉู! ๐",
                "ุงูุงู ูุดฺฉู ุฏุงุฑูุ ุงูุง ุฎูุดุญุงูู ฺฉู ุจุงูุงู ุญุฑู ูโุฒู! ๐"
            ]
            return random.choice(responses)