"""
Ù…Ø¯ÛŒØ± Ø¯ÛŒØªØ§Ø³Øª Ùˆ Ù¾Ø±Ø§Ù…Ù¾Øª Ø±ÙˆØ¨Ø§Ù‡
Ù…Ø³Ø¦ÙˆÙ„ Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒØŒ ØªØ­Ù„ÛŒÙ„ Ùˆ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´ÛŒ
"""

import json
import os
from datetime import datetime
from typing import Dict, List, Optional
import random

class DatasetManager:
    def __init__(self):
        self.datasets_dir = "data/datasets"
        self.prompts_dir = "data/prompts"
        
        # Ø§ÛŒØ¬Ø§Ø¯ Ø¯Ø§ÛŒØ±Ú©ØªÙˆØ±ÛŒâ€ŒÙ‡Ø§
        os.makedirs(self.datasets_dir, exist_ok=True)
        os.makedirs(self.prompts_dir, exist_ok=True)
        
        # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯ÛŒØªØ§Ø³Øªâ€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯
        self.conversation_patterns = self._load_conversation_patterns()
        self.emotion_responses = self._load_emotion_responses()
        self.topic_knowledge = self._load_topic_knowledge()
        self.prompt_templates = self._load_prompt_templates()
        
        print("ğŸ“Š Ù…Ø¯ÛŒØ± Ø¯ÛŒØªØ§Ø³Øª Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø´Ø¯")
    
    def _load_conversation_patterns(self) -> List[Dict]:
        """Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ù…Ú©Ø§Ù„Ù…Ù‡"""
        patterns_file = f"{self.datasets_dir}/conversation_patterns.json"
        
        if os.path.exists(patterns_file):
            with open(patterns_file, "r", encoding="utf-8") as f:
                return json.load(f)
        
        # Ø§ÛŒØ¬Ø§Ø¯ Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ù¾Ø§ÛŒÙ‡
        default_patterns = [
            {
                "pattern": "greeting",
                "user_examples": ["Ø³Ù„Ø§Ù…", "Ø¯Ø±ÙˆØ¯", "ØµØ¨Ø­ Ø¨Ø®ÛŒØ±", "Ø³Ù„Ø§Ù… Ø±ÙˆØ¨Ø§Ù‡"],
                "response_style": "Ø¯ÙˆØ³ØªØ§Ù†Ù‡ Ùˆ Ú¯Ø±Ù…",
                "responses": [
                    "Ø³Ù„Ø§Ù…! Ø®ÙˆØ´ Ø¢Ù…Ø¯ÛŒ! Ú†Ø·ÙˆØ±ÛŒØŸ ğŸ˜Š",
                    "Ø¯Ø±ÙˆØ¯ Ø¨Ø± ØªÙˆ! Ø­Ø§Ù„Øª Ú†Ø·ÙˆØ±Ù‡ØŸ",
                    "Ø³Ù„Ø§Ù… Ø¹Ø²ÛŒØ²Ù…! Ú†Ù‡ Ø®Ø¨Ø±ØŸ"
                ]
            }
        ]
        
        self._save_json(patterns_file, default_patterns)
        return default_patterns
    
    def _load_emotion_responses(self) -> Dict:
        """Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù¾Ø§Ø³Ø®â€ŒÙ‡Ø§ÛŒ Ø§Ø­Ø³Ø§Ø³ÛŒ"""
        emotions_file = f"{self.datasets_dir}/emotion_responses.json"
        
        if os.path.exists(emotions_file):
            with open(emotions_file, "r", encoding="utf-8") as f:
                return json.load(f)
        
        # Ø§ÛŒØ¬Ø§Ø¯ Ù¾Ø§Ø³Ø®â€ŒÙ‡Ø§ÛŒ Ø§Ø­Ø³Ø§Ø³ÛŒ Ù¾Ø§ÛŒÙ‡
        default_emotions = {
            "happy": {
                "indicators": ["Ø®ÙˆØ´Ø­Ø§Ù„Ù…", "Ø¹Ø§Ù„ÛŒÙ‡", "ÙÙˆÙ‚â€ŒØ§Ù„Ø¹Ø§Ø¯Ù‡", "ğŸ˜Š", "ğŸ˜„", "ğŸ‰"],
                "responses": [
                    "Ú†Ù‡ Ø®Ø¨Ø± Ø®ÙˆØ¨ÛŒ! Ù…Ù†Ù… Ø®ÙˆØ´Ø­Ø§Ù„Ù… ğŸ˜Š",
                    "Ø¹Ø§Ù„ÛŒÙ‡! Ø§ÛŒÙ† Ø§Ù†Ø±Ú˜ÛŒ Ù…Ø«Ø¨Øª Ø±Ùˆ Ø¯ÙˆØ³Øª Ø¯Ø§Ø±Ù…!",
                    "ÙˆØ§Ù‚Ø¹Ø§Ù‹ Ø®ÙˆØ´Ø­Ø§Ù„â€ŒÚ©Ù†Ù†Ø¯Ù‡ Ø§Ø³Øª! ğŸ‰"
                ]
            },
            "sad": {
                "indicators": ["Ù†Ø§Ø±Ø§Ø­ØªÙ…", "ØºÙ…Ú¯ÛŒÙ†Ù…", "Ø¨Ø¯", "ğŸ˜¢", "ğŸ˜"],
                "responses": [
                    "Ù…ØªÙˆØ¬Ù‡ Ù…ÛŒâ€ŒØ´Ù… Ú©Ù‡ Ù†Ø§Ø±Ø§Ø­ØªÛŒ. Ù…ÛŒâ€ŒØ®ÙˆØ§ÛŒ Ø¯Ø±Ø¨Ø§Ø±Ù‡â€ŒØ´ Ø­Ø±Ù Ø¨Ø²Ù†ÛŒÙ…ØŸ ğŸ’™",
                    "Ú¯Ø§Ù‡ÛŒ Ù‡Ù…Ù‡ Ù…Ø§ Ø±ÙˆØ²Ù‡Ø§ÛŒ Ø³Ø®ØªÛŒ Ø¯Ø§Ø±ÛŒÙ…. Ø§ÛŒÙ†Ø¬Ø§Ù… ØªØ§ Ú¯ÙˆØ´Øª Ø¨Ø¯Ù…",
                    "Ø­Ø³ Ù…ÛŒâ€ŒÚ©Ù†Ù… Ú©Ù‡ Ú†ÛŒØ²ÛŒ Ø¢Ø²Ø§Ø±Øª Ù…ÛŒâ€ŒØ¯Ù‡. Ù…ÛŒâ€ŒØªÙˆÙ†Ù… Ú©Ù…Ú© Ú©Ù†Ù…ØŸ"
                ]
            },
            "curious": {
                "indicators": ["Ú†Ø±Ø§", "Ú†Ø·ÙˆØ±", "Ú†ÛŒØ³Øª", "ØŸ", "Ú©Ù†Ø¬Ú©Ø§ÙˆÙ…"],
                "responses": [
                    "Ø³Ø¤Ø§Ù„ Ø¬Ø§Ù„Ø¨ÛŒ! Ø¨Ø°Ø§Ø± Ø¨Ø±Ø§Øª ØªÙˆØ¶ÛŒØ­ Ø¨Ø¯Ù… ğŸ¤”",
                    "Ú©Ù†Ø¬Ú©Ø§ÙˆÛŒ Ø®ÙˆØ¨ÛŒÙ‡! Ø§ÛŒÙ† Ú†ÛŒØ²ÛŒ Ú©Ù‡ Ù…ÛŒâ€ŒÙ¾Ø±Ø³ÛŒ...",
                    "Ø¹Ø§Ù„ÛŒÙ‡ Ú©Ù‡ Ù…ÛŒâ€ŒÙ¾Ø±Ø³ÛŒ! Ø§ÛŒÙ†Ø·ÙˆØ±ÛŒ ÛŒØ§Ø¯ Ù…ÛŒâ€ŒÚ¯ÛŒØ±ÛŒÙ…"
                ]
            }
        }
        
        self._save_json(emotions_file, default_emotions)
        return default_emotions
    
    def _load_topic_knowledge(self) -> Dict:
        """Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ù†Ø´ Ù…ÙˆØ¶ÙˆØ¹ÛŒ"""
        topics_file = f"{self.datasets_dir}/topic_knowledge.json"
        
        if os.path.exists(topics_file):
            with open(topics_file, "r", encoding="utf-8") as f:
                return json.load(f)
        
        # Ø§ÛŒØ¬Ø§Ø¯ Ø¯Ø§Ù†Ø´ Ù…ÙˆØ¶ÙˆØ¹ÛŒ Ù¾Ø§ÛŒÙ‡
        default_topics = {
            "programming": {
                "keywords": ["Ø¨Ø±Ù†Ø§Ù…Ù‡â€ŒÙ†ÙˆÛŒØ³ÛŒ", "Ú©Ø¯", "Ù¾Ø§ÛŒØªÙˆÙ†", "Ø¬Ø§ÙˆØ§", "ÙˆØ¨"],
                "intro_responses": [
                    "Ø¨Ø±Ù†Ø§Ù…Ù‡â€ŒÙ†ÙˆÛŒØ³ÛŒ Ø¹Ø§Ø´Ù‚Ø´Ù…! ğŸ’» Ú†Ù‡ Ø²Ø¨Ø§Ù†ÛŒ Ù…ÛŒâ€ŒØ®ÙˆØ§ÛŒ ÛŒØ§Ø¯ Ø¨Ú¯ÛŒØ±ÛŒØŸ",
                    "Ú©Ø¯Ù†ÙˆÛŒØ³ÛŒ Ø¯Ù†ÛŒØ§ÛŒ Ø¬Ø°Ø§Ø¨ÛŒÙ‡! Ø§Ø² Ú©Ø¬Ø§ Ø´Ø±ÙˆØ¹ Ú©Ù†ÛŒÙ…ØŸ"
                ],
                "difficulty_levels": {
                    "beginner": "Ø¨ÛŒØ§ Ø¨Ø§ Ù…ÙØ§Ù‡ÛŒÙ… Ø³Ø§Ø¯Ù‡ Ø´Ø±ÙˆØ¹ Ú©Ù†ÛŒÙ…",
                    "intermediate": "Ø­Ø§Ù„Ø§ Ù…ÛŒâ€ŒØªÙˆÙ†ÛŒÙ… ÙˆØ§Ø±Ø¯ Ø¬Ø²Ø¦ÛŒØ§Øª Ø¨Ø´ÛŒÙ…",
                    "advanced": "Ø¨Ø­Ø«â€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡â€ŒØªØ± Ø±Ùˆ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒÙ…"
                }
            }
        }
        
        self._save_json(topics_file, default_topics)
        return default_topics
    
    def _load_prompt_templates(self) -> Dict:
        """Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù‚Ø§Ù„Ø¨â€ŒÙ‡Ø§ÛŒ Ù¾Ø±Ø§Ù…Ù¾Øª"""
        prompts_file = f"{self.prompts_dir}/templates.json"
        
        if os.path.exists(prompts_file):
            with open(prompts_file, "r", encoding="utf-8") as f:
                return json.load(f)
        
        # Ø§ÛŒØ¬Ø§Ø¯ Ù‚Ø§Ù„Ø¨â€ŒÙ‡Ø§ÛŒ Ù¾Ø±Ø§Ù…Ù¾Øª Ù¾Ø§ÛŒÙ‡
        default_templates = {
            "base_personality": """ØªÙˆ Ø±ÙˆØ¨Ø§Ù‡ Ù‡Ø³ØªÛŒØŒ ÛŒÚ© Ø¯Ø³ØªÛŒØ§Ø± Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ø´Ø®ØµÛŒ Ú©Ù‡:
- Ø´Ø®ØµÛŒØª Ø¯ÙˆØ³ØªØ§Ù†Ù‡ Ùˆ ØµÙ…ÛŒÙ…ÛŒ Ø¯Ø§Ø±ÛŒ
- Ø§Ø² ØªØ¬Ø±Ø¨ÛŒØ§Øª Ù‚Ø¨Ù„ÛŒ ÛŒØ§Ø¯ Ù…ÛŒâ€ŒÚ¯ÛŒØ±ÛŒ
- Ø¨Ø§ Ø§Ø­Ø³Ø§Ø³Ø§Øª Ú©Ø§Ø±Ø¨Ø± Ù‡Ù…Ø¯Ù„ÛŒ Ù…ÛŒâ€ŒÚ©Ù†ÛŒ
- Ù¾Ø§Ø³Ø®â€ŒÙ‡Ø§ÛŒØª Ø®Ù„Ø§Ù‚Ø§Ù†Ù‡ Ùˆ Ù…ÙÛŒØ¯ Ù‡Ø³ØªÙ†Ø¯
- Ø¨Ù‡ ÙØ§Ø±Ø³ÛŒ Ùˆ Ø¨Ø§ Ù„Ø­Ù† Ú¯Ø±Ù… ØµØ­Ø¨Øª Ù…ÛŒâ€ŒÚ©Ù†ÛŒ
- Ø§Ø² Ø§ÛŒÙ…ÙˆØ¬ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒ ØªØ§ Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§Øª Ø¬Ø°Ø§Ø¨â€ŒØªØ± Ø¨Ø§Ø´Ù†Ø¯""",
            
            "emotional_context": """ÙˆØ¶Ø¹ÛŒØª Ø§Ø­Ø³Ø§Ø³ÛŒ Ú©Ø§Ø±Ø¨Ø±: {emotion}
Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ù¾Ø§Ø³Ø®: {emotion_guide}
Ø³Ø¨Ú© Ù…Ù†Ø§Ø³Ø¨: {response_style}""",
            
            "topic_context": """Ù…ÙˆØ¶ÙˆØ¹ Ù…Ú©Ø§Ù„Ù…Ù‡: {topic}
Ø³Ø·Ø­ Ø¯Ø§Ù†Ø´ Ú©Ø§Ø±Ø¨Ø±: {user_level}
Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…Ø±ØªØ¨Ø·: {topic_info}""",
            
            "memory_context": """ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ù…Ú©Ø§Ù„Ù…Ø§Øª:
{conversation_history}

Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø´Ø®ØµÛŒ Ú©Ø§Ø±Ø¨Ø±:
{user_preferences}"""
        }
        
        self._save_json(prompts_file, default_templates)
        return default_templates
    
    def analyze_user_message(self, message: str, context: List[Dict] = None) -> Dict:
        """ØªØ­Ù„ÛŒÙ„ Ù¾ÛŒØ§Ù… Ú©Ø§Ø±Ø¨Ø± Ùˆ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø·Ù„Ø§Ø¹Ø§Øª"""
        analysis = {
            "emotion": self._detect_emotion(message),
            "topic": self._detect_topic(message),
            "intent": self._detect_intent(message),
            "complexity": self._assess_complexity(message),
            "patterns": self._find_patterns(message, context)
        }
        
        return analysis
    
    def _detect_emotion(self, message: str) -> str:
        """ØªØ´Ø®ÛŒØµ Ø§Ø­Ø³Ø§Ø³Ø§Øª Ù¾ÛŒØ§Ù…"""
        message_lower = message.lower()
        
        for emotion, data in self.emotion_responses.items():
            for indicator in data["indicators"]:
                if indicator in message_lower:
                    return emotion
        
        return "neutral"
    
    def _detect_topic(self, message: str) -> Optional[str]:
        """ØªØ´Ø®ÛŒØµ Ù…ÙˆØ¶ÙˆØ¹ Ù¾ÛŒØ§Ù…"""
        message_lower = message.lower()
        
        for topic, data in self.topic_knowledge.items():
            for keyword in data["keywords"]:
                if keyword in message_lower:
                    return topic
        
        return None
    
    def _detect_intent(self, message: str) -> str:
        """ØªØ´Ø®ÛŒØµ Ù‡Ø¯Ù Ù¾ÛŒØ§Ù…"""
        message_lower = message.lower()
        
        if any(word in message_lower for word in ["Ú†ÛŒØ³Øª", "Ú†ÛŒÙ‡", "ØªØ¹Ø±ÛŒÙ", "ÛŒØ¹Ù†ÛŒ Ú†ÛŒ"]):
            return "definition"
        elif any(word in message_lower for word in ["Ú†Ø·ÙˆØ±", "Ú†Ú¯ÙˆÙ†Ù‡", "Ø±Ø§Ù‡"]):
            return "how_to"
        elif "ØŸ" in message:
            return "question"
        elif any(word in message_lower for word in ["Ú©Ù…Ú©", "Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒÛŒ", "ÛŒØ§Ø¯ Ø¨Ø¯Ù‡"]):
            return "help"
        else:
            return "conversation"
    
    def _assess_complexity(self, message: str) -> str:
        """Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ù¾ÛŒÚ†ÛŒØ¯Ú¯ÛŒ Ù¾ÛŒØ§Ù…"""
        word_count = len(message.split())
        
        if word_count <= 3:
            return "simple"
        elif word_count <= 10:
            return "medium"
        else:
            return "complex"
    
    def _find_patterns(self, message: str, context: List[Dict] = None) -> List[str]:
        """ÛŒØ§ÙØªÙ† Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ù…Ú©Ø§Ù„Ù…Ù‡"""
        patterns = []
        
        for pattern in self.conversation_patterns:
            for example in pattern["user_examples"]:
                if example.lower() in message.lower():
                    patterns.append(pattern["pattern"])
                    break
        
        return patterns
    
    def generate_enhanced_prompt(self, message: str, analysis: Dict, context: List[Dict] = None, personality: Dict = None) -> str:
        """ØªÙˆÙ„ÛŒØ¯ Ù¾Ø±Ø§Ù…Ù¾Øª Ø¨Ù‡Ø¨ÙˆØ¯ ÛŒØ§ÙØªÙ‡"""
        
        # Ø´Ø±ÙˆØ¹ Ø¨Ø§ Ø´Ø®ØµÛŒØª Ù¾Ø§ÛŒÙ‡
        prompt = self.prompt_templates["base_personality"]
        
        # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† context Ø§Ø­Ø³Ø§Ø³ÛŒ
        if analysis["emotion"] != "neutral":
            emotion_data = self.emotion_responses.get(analysis["emotion"], {})
            emotion_context = self.prompt_templates["emotional_context"].format(
                emotion=analysis["emotion"],
                emotion_guide=f"Ú©Ø§Ø±Ø¨Ø± {analysis['emotion']} Ø¨Ù‡ Ù†Ø¸Ø± Ù…ÛŒâ€ŒØ±Ø³Ø¯",
                response_style=emotion_data.get("responses", ["Ù¾Ø§Ø³Ø® Ù…Ù†Ø§Ø³Ø¨ Ø¨Ø¯Ù‡"])[0]
            )
            prompt += f"\n\n{emotion_context}"
        
        # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† context Ù…ÙˆØ¶ÙˆØ¹ÛŒ
        if analysis["topic"]:
            topic_data = self.topic_knowledge.get(analysis["topic"], {})
            topic_context = self.prompt_templates["topic_context"].format(
                topic=analysis["topic"],
                user_level="Ù…ØªÙˆØ³Ø·",  # Ù…ÛŒâ€ŒØªÙˆÙ†ÛŒÙ… Ø¨Ø¹Ø¯Ø§Ù‹ Ù¾ÛŒØ´Ø±ÙØªÙ‡â€ŒØªØ± Ú©Ù†ÛŒÙ…
                topic_info=str(topic_data.get("keywords", []))
            )
            prompt += f"\n\n{topic_context}"
        
        # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† ØªØ§Ø±ÛŒØ®Ú†Ù‡
        if context:
            history = "\n".join([f"- {item.get('content', '')[:50]}..." for item in context[-3:]])
            memory_context = self.prompt_templates["memory_context"].format(
                conversation_history=history,
                user_preferences=str(personality.get("favorite_topics", [])) if personality else "Ù†Ø§Ù…Ø´Ø®Øµ"
            )
            prompt += f"\n\n{memory_context}"
        
        # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ø®Ø§Øµ
        intent_guides = {
            "definition": "ØªÙˆØ¶ÛŒØ­ Ø³Ø§Ø¯Ù‡ Ùˆ Ú©Ø§Ø±Ø¨Ø±Ø¯ÛŒ Ø¨Ø¯Ù‡ØŒ Ø¨Ø§ Ù…Ø«Ø§Ù„",
            "how_to": "Ù…Ø±Ø§Ø­Ù„ Ø±Ø§ Ú¯Ø§Ù… Ø¨Ù‡ Ú¯Ø§Ù… ØªÙˆØ¶ÛŒØ­ Ø¨Ø¯Ù‡",
            "question": "Ù¾Ø§Ø³Ø® Ú©Ø§Ù…Ù„ Ùˆ Ù…ÙÛŒØ¯ Ø¨Ø¯Ù‡",
            "help": "Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒÛŒ Ø¹Ù…Ù„ÛŒ Ùˆ Ù‚Ø§Ø¨Ù„ Ø§Ø¬Ø±Ø§ Ø§Ø±Ø§Ø¦Ù‡ Ø¨Ø¯Ù‡"
        }
        
        if analysis["intent"] in intent_guides:
            prompt += f"\n\nØ±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ù¾Ø§Ø³Ø®: {intent_guides[analysis['intent']]}"
        
        # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ù¾ÛŒØ§Ù… Ú©Ø§Ø±Ø¨Ø±
        prompt += f"\n\nÚ©Ø§Ø±Ø¨Ø±: {message}\nØ±ÙˆØ¨Ø§Ù‡:"
        
        return prompt
    
    def get_similar_responses(self, message: str, analysis: Dict) -> List[str]:
        """Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ù¾Ø§Ø³Ø®â€ŒÙ‡Ø§ÛŒ Ù…Ø´Ø§Ø¨Ù‡ Ø§Ø² dataset"""
        similar_responses = []
        
        # Ø¬Ø³ØªØ¬Ùˆ Ø¯Ø± Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ù…Ú©Ø§Ù„Ù…Ù‡
        for pattern in self.conversation_patterns:
            if any(keyword in message.lower() for keyword in pattern.get("user_examples", [])):
                similar_responses.extend(pattern.get("responses", []))
        
        # Ø¬Ø³ØªØ¬Ùˆ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§Ø­Ø³Ø§Ø³
        if analysis["emotion"] != "neutral":
            emotion_data = self.emotion_responses.get(analysis["emotion"])
            if emotion_data:
                similar_responses.extend(emotion_data.get("responses", []))
        
        return similar_responses[:5]  # Ø­Ø¯Ø§Ú©Ø«Ø± 5 Ù…ÙˆØ±Ø¯
    
    def get_conversation_patterns(self, analysis: Dict) -> List[Dict]:
        """Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ù…Ú©Ø§Ù„Ù…Ù‡ Ù…Ø±ØªØ¨Ø·"""
        relevant_patterns = []
        
        for pattern in self.conversation_patterns:
            # Ø¨Ø±Ø±Ø³ÛŒ ØªØ·Ø¨ÛŒÙ‚ Ø¨Ø§ Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ ØªØ´Ø®ÛŒØµ Ø¯Ø§Ø¯Ù‡ Ø´Ø¯Ù‡
            if pattern["pattern"] in analysis.get("patterns", []):
                relevant_patterns.append(pattern)
        
        return relevant_patterns[:3]  # Ø­Ø¯Ø§Ú©Ø«Ø± 3 Ù…ÙˆØ±Ø¯
        """Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ù¾Ø§Ø³Ø® Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§Ù„Ú¯ÙˆÙ‡Ø§"""
        
        # Ø§Ú¯Ø± Ø³Ø¤Ø§Ù„ Ù¾ÛŒÚ†ÛŒØ¯Ù‡ ÛŒØ§ ØªØ®ØµØµÛŒ Ø¨Ø§Ø´Ù‡ØŒ Ø§Ø² Ø¯ÛŒØªØ§Ø³Øª Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù†Ú©Ù†
        if analysis["complexity"] in ["complex", "technical"]:
            return None
        
        # Ø§Ú¯Ø± Ù…ÙˆØ¶ÙˆØ¹ Ø®Ø§ØµÛŒ Ø¯Ø§Ø±Ù‡ (Ù…Ø«Ù„ Ø¢Ø¨ Ùˆ Ù‡ÙˆØ§ØŒ Ø§Ø®Ø¨Ø§Ø±ØŒ Ø§Ø·Ù„Ø§Ø¹Ø§Øª ÙÙ†ÛŒ)ØŒ Ø§Ø² Ø¯ÛŒØªØ§Ø³Øª Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù†Ú©Ù†
        if analysis["topic"] and analysis["topic"] not in ["conversation", "general"]:
            return None
        
        # ÙÙ‚Ø· Ø¨Ø±Ø§ÛŒ Ù…Ú©Ø§Ù„Ù…Ø§Øª Ø³Ø§Ø¯Ù‡ Ùˆ Ø¹Ù…ÙˆÙ…ÛŒ Ø§Ø² Ø¯ÛŒØªØ§Ø³Øª Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†
        if analysis["intent"] != "conversation":
            return None
        
        # Ø§Ú¯Ø± Ø§Ù„Ú¯ÙˆÛŒ Ù…Ø´Ø®ØµÛŒ Ù¾ÛŒØ¯Ø§ Ø´Ø¯
        if analysis["patterns"]:
            pattern_name = analysis["patterns"][0]
            for pattern in self.conversation_patterns:
                if pattern["pattern"] == pattern_name:
                    return random.choice(pattern["responses"])
        
        # Ø§Ú¯Ø± Ø§Ø­Ø³Ø§Ø³ Ø®Ø§ØµÛŒ ØªØ´Ø®ÛŒØµ Ø¯Ø§Ø¯Ù‡ Ø´Ø¯
        if analysis["emotion"] != "neutral":
            emotion_data = self.emotion_responses.get(analysis["emotion"])
            if emotion_data:
                return random.choice(emotion_data["responses"])
        
        return None
    
    def learn_from_interaction(self, user_message: str, ai_response: str, feedback: Optional[int] = None):
        """ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ø§Ø² ØªØ¹Ø§Ù…Ù„"""
        
        # ØªØ­Ù„ÛŒÙ„ Ú©ÛŒÙÛŒØª Ù¾Ø§Ø³Ø®
        quality_score = feedback if feedback else self._assess_response_quality(user_message, ai_response)
        
        # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± Ø¯ÛŒØªØ§Ø³Øª ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ
        learning_entry = {
            "timestamp": datetime.now().isoformat(),
            "user_message": user_message,
            "ai_response": ai_response,
            "quality_score": quality_score,
            "analysis": self.analyze_user_message(user_message)
        }
        
        # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± ÙØ§ÛŒÙ„
        learning_file = f"{self.datasets_dir}/learning_data.jsonl"
        with open(learning_file, "a", encoding="utf-8") as f:
            f.write(json.dumps(learning_entry, ensure_ascii=False) + "\n")
        
        # Ø§Ú¯Ø± Ù¾Ø§Ø³Ø® Ø®ÙˆØ¨ Ø¨ÙˆØ¯ØŒ Ø¨Ù‡ Ø§Ù„Ú¯ÙˆÙ‡Ø§ Ø§Ø¶Ø§ÙÙ‡ Ú©Ù†
        if quality_score >= 4:
            self._add_to_patterns(user_message, ai_response, learning_entry["analysis"])
    
    def _assess_response_quality(self, user_message: str, ai_response: str) -> int:
        """Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ø®ÙˆØ¯Ú©Ø§Ø± Ú©ÛŒÙÛŒØª Ù¾Ø§Ø³Ø®"""
        score = 3  # Ù¾Ø§ÛŒÙ‡
        
        # Ø¨Ø±Ø±Ø³ÛŒ Ø·ÙˆÙ„ Ù…Ù†Ø§Ø³Ø¨
        if 10 <= len(ai_response) <= 500:
            score += 1
        
        # Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¬ÙˆØ¯ Ø§ÛŒÙ…ÙˆØ¬ÛŒ (Ù†Ø´Ø§Ù† Ø¯ÙˆØ³ØªØ§Ù†Ù‡ Ø¨ÙˆØ¯Ù†)
        if any(emoji in ai_response for emoji in ["ğŸ˜Š", "ğŸ˜„", "ğŸ¦Š", "ğŸ’™", "ğŸ‰", "ğŸ¤”"]):
            score += 1
        
        # Ø¨Ø±Ø±Ø³ÛŒ Ù¾Ø§Ø³Ø® Ø¨Ù‡ Ø³Ø¤Ø§Ù„
        if "ØŸ" in user_message and len(ai_response) > 20:
            score += 1
        
        return min(score, 5)
    
    def _add_to_patterns(self, user_message: str, ai_response: str, analysis: Dict):
        """Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø¨Ù‡ Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ù…Ú©Ø§Ù„Ù…Ù‡"""
        
        # Ø§Ú¯Ø± Ø§Ù„Ú¯ÙˆÛŒ Ø¬Ø¯ÛŒØ¯ÛŒ Ø§Ø³Øª
        if not analysis["patterns"]:
            new_pattern = {
                "pattern": f"custom_{len(self.conversation_patterns)}",
                "user_examples": [user_message],
                "response_style": "ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ø´Ø¯Ù‡ Ø§Ø² ØªØ¹Ø§Ù…Ù„",
                "responses": [ai_response]
            }
            self.conversation_patterns.append(new_pattern)
            
            # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± ÙØ§ÛŒÙ„
            patterns_file = f"{self.datasets_dir}/conversation_patterns.json"
            self._save_json(patterns_file, self.conversation_patterns)
    
    def _save_json(self, filepath: str, data):
        """Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø§Ø¯Ù‡ Ø¯Ø± ÙØ§ÛŒÙ„ JSON"""
        with open(filepath, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
    
    def get_stats(self) -> Dict:
        """Ø¢Ù…Ø§Ø± Ø¯ÛŒØªØ§Ø³Øª"""
        return {
            "conversation_patterns": len(self.conversation_patterns),
            "emotion_types": len(self.emotion_responses),
            "topics": len(self.topic_knowledge),
            "prompt_templates": len(self.prompt_templates)
        }