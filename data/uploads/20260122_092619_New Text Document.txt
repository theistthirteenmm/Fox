import asyncio
import json
import requests
import re
from typing import Dict, List, Optional
from datetime import datetime
import os
import random
from .web_search import WebSearchEngine
from .dataset_manager import DatasetManager
from .code_analyzer import code_analyzer

class AIBrain:
    def __init__(self):
        self.model_name = "partai/dorna-llama3:8b-instruct-q8_0"  # Ù…Ø¯Ù„ ÙØ§Ø±Ø³ÛŒ Ø¨Ù‡ÛŒÙ†Ù‡
        self.ollama_url = "http://localhost:11434"
        self.is_model_loaded = False
        self.conversation_history = []
        self.learning_data = []
        
        # Ø³ÛŒØ³ØªÙ… Ø¬Ø³ØªØ¬ÙˆÛŒ ÙˆØ¨
        self.web_search = WebSearchEngine()
        self.web_enabled = True
        
        # Ø³ÛŒØ³ØªÙ… Ø¯ÛŒØªØ§Ø³Øª Ùˆ Ù¾Ø±Ø§Ù…Ù¾Øª
        self.dataset_manager = DatasetManager()
        
    def is_loaded(self) -> bool:
        """Ø¨Ø±Ø±Ø³ÛŒ Ø¢Ù…Ø§Ø¯Ù‡ Ø¨ÙˆØ¯Ù† Ù…Ø¯Ù„"""
        try:
            # ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø¨Ø±Ø§ÛŒ Ø¹Ø¯Ù… Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² proxy Ø¨Ø±Ø§ÛŒ localhost
            proxies = {'http': None, 'https': None}
            
            response = requests.get(f"{self.ollama_url}/api/tags", proxies=proxies)
            if response.status_code == 200:
                models = response.json().get("models", [])
                return any(model["name"].startswith(self.model_name) for model in models)
        except:
            pass
        return False
    
    async def initialize_model(self):
        """Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø§ÙˆÙ„ÛŒÙ‡ Ù…Ø¯Ù„"""
        print("ğŸ§  Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ...")
        
        if not self.is_loaded():
            print(f"ğŸ“¥ Ø¯Ø± Ø­Ø§Ù„ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…Ø¯Ù„ {self.model_name}...")
            # Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…Ø¯Ù„ Ø§Ú¯Ø± ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯
            await self._pull_model()
        
        # ØªØ³Øª Ø§ÙˆÙ„ÛŒÙ‡ Ù…Ø¯Ù„ Ø¨Ø§ prompt Ø¨Ù‡ØªØ±
        test_prompt = """ØªÙˆ Ø±ÙˆØ¨Ø§Ù‡ Ù‡Ø³ØªÛŒØŒ ÛŒÚ© Ø¯Ø³ØªÛŒØ§Ø± Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ ÙØ§Ø±Ø³ÛŒ. Ø¨Ù‡ ÙØ§Ø±Ø³ÛŒ Ù¾Ø§Ø³Ø® Ø¨Ø¯Ù‡.

Ú©Ø§Ø±Ø¨Ø±: Ø³Ù„Ø§Ù…
Ø±ÙˆØ¨Ø§Ù‡:"""
        
        test_response = await self._generate_raw(test_prompt)
        if test_response and len(test_response.strip()) > 0:
            self.is_model_loaded = True
            print(f"âœ… Ù…Ø¯Ù„ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯! Ù¾Ø§Ø³Ø® ØªØ³Øª: {test_response[:50]}...")
        else:
            print("âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„")
            # Ø­ØªÛŒ Ø§Ú¯Ø± ØªØ³Øª Ù†Ø§Ù…ÙˆÙÙ‚ Ø¨ÙˆØ¯ØŒ Ù…Ø¯Ù„ Ø±Ø§ loaded Ø¯Ø± Ù†Ø¸Ø± Ø¨Ú¯ÛŒØ±
            self.is_model_loaded = True
    
    async def _pull_model(self):
        """Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…Ø¯Ù„ Ø§Ø² Ollama"""
        try:
            # ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø¨Ø±Ø§ÛŒ Ø¹Ø¯Ù… Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² proxy Ø¨Ø±Ø§ÛŒ localhost
            proxies = {'http': None, 'https': None}
            
            response = requests.post(
                f"{self.ollama_url}/api/pull",
                json={"name": self.model_name},
                stream=True,
                proxies=proxies
            )
            
            for line in response.iter_lines():
                if line:
                    data = json.loads(line)
                    if "status" in data:
                        print(f"ğŸ“Š {data['status']}")
                        
        except Exception as e:
            print(f"Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…Ø¯Ù„: {e}")
    
    async def generate_response(self, message: str, context: List[Dict] = None, personality: Dict = None) -> str:
        """ØªÙˆÙ„ÛŒØ¯ Ù¾Ø§Ø³Ø® Ø§ØµÙ„ÛŒ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø¯ÛŒØªØ§Ø³Øª"""
        
        # Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø§Ø² Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„
        if not self.is_model_loaded:
            print("ğŸ”„ Ù…Ø¯Ù„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù†Ø´Ø¯Ù‡ØŒ Ø¯Ø± Ø­Ø§Ù„ Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ...")
            await self.initialize_model()
        
        # Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¬ÙˆØ¯ Ú©Ø¯ Ø¯Ø± Ù¾ÛŒØ§Ù…
        code_analysis = self.analyze_user_code(message)
        
        # ØªØ­Ù„ÛŒÙ„ Ù¾ÛŒØ§Ù… Ú©Ø§Ø±Ø¨Ø±
        analysis = self.dataset_manager.analyze_user_message(message, context)
        print(f"ğŸ” ØªØ­Ù„ÛŒÙ„ Ù¾ÛŒØ§Ù…: {analysis}")
        
        # Ø¨Ø±Ø±Ø³ÛŒ Ù¾Ø§Ø³Ø® Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ Ø§Ø² Ø¯ÛŒØªØ§Ø³Øª
        suggested_response = self.dataset_manager.get_suggested_response(analysis)
        if suggested_response and analysis["intent"] == "conversation":
            print("ğŸ’¡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù¾Ø§Ø³Ø® Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ Ø¯ÛŒØªØ§Ø³Øª")